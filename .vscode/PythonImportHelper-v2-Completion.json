[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "urllib",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "urllib",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "isd.logger",
        "description": "isd.logger",
        "isExtraImport": true,
        "detail": "isd.logger",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "isdException",
        "importPath": "isd.exception",
        "description": "isd.exception",
        "isExtraImport": true,
        "detail": "isd.exception",
        "documentation": {}
    },
    {
        "label": "DataIngestionConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "DataValidationConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "ModelPusherConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "DataIngestionConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "DataValidationConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "ModelPusherConfig",
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "isExtraImport": true,
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "DataIngestionArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "DataIngestionArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "DataValidationArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelPusherArtifacts",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "DataIngestionArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "DataValidationArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerArtifact",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelPusherArtifacts",
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "isExtraImport": true,
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "S3Operation",
        "importPath": "isd.configuration.s3_operations",
        "description": "isd.configuration.s3_operations",
        "isExtraImport": true,
        "detail": "isd.configuration.s3_operations",
        "documentation": {}
    },
    {
        "label": "S3Operation",
        "importPath": "isd.configuration.s3_operations",
        "description": "isd.configuration.s3_operations",
        "isExtraImport": true,
        "detail": "isd.configuration.s3_operations",
        "documentation": {}
    },
    {
        "label": "S3Operation",
        "importPath": "isd.configuration.s3_operations",
        "description": "isd.configuration.s3_operations",
        "isExtraImport": true,
        "detail": "isd.configuration.s3_operations",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "isd.constant.training_pipeline",
        "description": "isd.constant.training_pipeline",
        "isExtraImport": true,
        "detail": "isd.constant.training_pipeline",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "isd.constant.training_pipeline",
        "description": "isd.constant.training_pipeline",
        "isExtraImport": true,
        "detail": "isd.constant.training_pipeline",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "isd.constant.training_pipeline",
        "description": "isd.constant.training_pipeline",
        "isExtraImport": true,
        "detail": "isd.constant.training_pipeline",
        "documentation": {}
    },
    {
        "label": "os,sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.sys",
        "description": "os.sys",
        "detail": "os.sys",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "read_yaml_file",
        "importPath": "isd.utils.main_utils",
        "description": "isd.utils.main_utils",
        "isExtraImport": true,
        "detail": "isd.utils.main_utils",
        "documentation": {}
    },
    {
        "label": "decodeImage",
        "importPath": "isd.utils.main_utils",
        "description": "isd.utils.main_utils",
        "isExtraImport": true,
        "detail": "isd.utils.main_utils",
        "documentation": {}
    },
    {
        "label": "encodeImageIntoBase64",
        "importPath": "isd.utils.main_utils",
        "description": "isd.utils.main_utils",
        "isExtraImport": true,
        "detail": "isd.utils.main_utils",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "isd.constant",
        "description": "isd.constant",
        "isExtraImport": true,
        "detail": "isd.constant",
        "documentation": {}
    },
    {
        "label": "boto3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "boto3",
        "description": "boto3",
        "detail": "boto3",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "ClientError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "Bucket",
        "importPath": "mypy_boto3_s3.service_resource",
        "description": "mypy_boto3_s3.service_resource",
        "isExtraImport": true,
        "detail": "mypy_boto3_s3.service_resource",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "read_csv",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "sys,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys.",
        "description": "sys.",
        "detail": "sys.",
        "documentation": {}
    },
    {
        "label": "DataIngestion",
        "importPath": "isd.components.data_ingestion",
        "description": "isd.components.data_ingestion",
        "isExtraImport": true,
        "detail": "isd.components.data_ingestion",
        "documentation": {}
    },
    {
        "label": "DataValidation",
        "importPath": "isd.components.data_validation",
        "description": "isd.components.data_validation",
        "isExtraImport": true,
        "detail": "isd.components.data_validation",
        "documentation": {}
    },
    {
        "label": "ModelTrainer",
        "importPath": "isd.components.model_trainer",
        "description": "isd.components.model_trainer",
        "isExtraImport": true,
        "detail": "isd.components.model_trainer",
        "documentation": {}
    },
    {
        "label": "ModelPusher",
        "importPath": "isd.components.model_pusher",
        "description": "isd.components.model_pusher",
        "isExtraImport": true,
        "detail": "isd.components.model_pusher",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "tritonclient.grpc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tritonclient.grpc",
        "description": "tritonclient.grpc",
        "detail": "tritonclient.grpc",
        "documentation": {}
    },
    {
        "label": "InferenceServerException",
        "importPath": "tritonclient.utils",
        "description": "tritonclient.utils",
        "isExtraImport": true,
        "detail": "tritonclient.utils",
        "documentation": {}
    },
    {
        "label": "preprocess",
        "importPath": "processing",
        "description": "processing",
        "isExtraImport": true,
        "detail": "processing",
        "documentation": {}
    },
    {
        "label": "postprocess",
        "importPath": "processing",
        "description": "processing",
        "isExtraImport": true,
        "detail": "processing",
        "documentation": {}
    },
    {
        "label": "render_box",
        "importPath": "render",
        "description": "render",
        "isExtraImport": true,
        "detail": "render",
        "documentation": {}
    },
    {
        "label": "render_filled_box",
        "importPath": "render",
        "description": "render",
        "isExtraImport": true,
        "detail": "render",
        "documentation": {}
    },
    {
        "label": "get_text_size",
        "importPath": "render",
        "description": "render",
        "isExtraImport": true,
        "detail": "render",
        "documentation": {}
    },
    {
        "label": "render_text",
        "importPath": "render",
        "description": "render",
        "isExtraImport": true,
        "detail": "render",
        "documentation": {}
    },
    {
        "label": "RAND_COLORS",
        "importPath": "render",
        "description": "render",
        "isExtraImport": true,
        "detail": "render",
        "documentation": {}
    },
    {
        "label": "COCOLabels",
        "importPath": "labels",
        "description": "labels",
        "isExtraImport": true,
        "detail": "labels",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "BoundingBox",
        "importPath": "boundingbox",
        "description": "boundingbox",
        "isExtraImport": true,
        "detail": "boundingbox",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "DeformConv2d",
        "importPath": "torchvision.ops",
        "description": "torchvision.ops",
        "isExtraImport": true,
        "detail": "torchvision.ops",
        "documentation": {}
    },
    {
        "label": "roi_pool",
        "importPath": "torchvision.ops",
        "description": "torchvision.ops",
        "isExtraImport": true,
        "detail": "torchvision.ops",
        "documentation": {}
    },
    {
        "label": "roi_align",
        "importPath": "torchvision.ops",
        "description": "torchvision.ops",
        "isExtraImport": true,
        "detail": "torchvision.ops",
        "documentation": {}
    },
    {
        "label": "ps_roi_pool",
        "importPath": "torchvision.ops",
        "description": "torchvision.ops",
        "isExtraImport": true,
        "detail": "torchvision.ops",
        "documentation": {}
    },
    {
        "label": "ps_roi_align",
        "importPath": "torchvision.ops",
        "description": "torchvision.ops",
        "isExtraImport": true,
        "detail": "torchvision.ops",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ExifTags",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "letterbox",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndLabels",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.datasets",
        "description": "utils.datasets",
        "isExtraImport": true,
        "detail": "utils.datasets",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_coords",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "set_logging",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyn2xy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "bbox_alpha_iou",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "box_giou",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "box_diou",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "box_ciou",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "apply_classifier",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "set_logging",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "set_logging",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_class_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_image_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_class_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_image_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "color_list",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_one_box",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_one_box",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_study_txt",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_evolution",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_evolution",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "time_synchronized",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_synchronized",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "init_torch_seeds",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "load_classifier",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_synchronized",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TracedModel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_synchronized",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TracedModel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "Conv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.google_utils",
        "description": "utils.google_utils",
        "isExtraImport": true,
        "detail": "utils.google_utils",
        "documentation": {}
    },
    {
        "label": "gsutil_getsize",
        "importPath": "utils.google_utils",
        "description": "utils.google_utils",
        "isExtraImport": true,
        "detail": "utils.google_utils",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.google_utils",
        "description": "utils.google_utils",
        "isExtraImport": true,
        "detail": "utils.google_utils",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.google_utils",
        "description": "utils.google_utils",
        "isExtraImport": true,
        "detail": "utils.google_utils",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.google_utils",
        "description": "utils.google_utils",
        "isExtraImport": true,
        "detail": "utils.google_utils",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "End2End",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "check_anchor_order",
        "importPath": "utils.autoanchor",
        "description": "utils.autoanchor",
        "isExtraImport": true,
        "detail": "utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_anchors",
        "importPath": "utils.autoanchor",
        "description": "utils.autoanchor",
        "isExtraImport": true,
        "detail": "utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_anchors",
        "importPath": "utils.autoanchor",
        "description": "utils.autoanchor",
        "isExtraImport": true,
        "detail": "utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "SigmoidBin",
        "importPath": "utils.loss",
        "description": "utils.loss",
        "isExtraImport": true,
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "importPath": "utils.loss",
        "description": "utils.loss",
        "isExtraImport": true,
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLossOTA",
        "importPath": "utils.loss",
        "description": "utils.loss",
        "isExtraImport": true,
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "importPath": "utils.loss",
        "description": "utils.loss",
        "isExtraImport": true,
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLossAuxOTA",
        "importPath": "utils.loss",
        "description": "utils.loss",
        "isExtraImport": true,
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "importPath": "wandb_utils",
        "description": "wandb_utils",
        "isExtraImport": true,
        "detail": "wandb_utils",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "onnx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "onnx",
        "description": "onnx",
        "detail": "onnx",
        "documentation": {}
    },
    {
        "label": "shape_inference",
        "importPath": "onnx",
        "description": "onnx",
        "isExtraImport": true,
        "detail": "onnx",
        "documentation": {}
    },
    {
        "label": "kmeans",
        "importPath": "scipy.cluster.vq",
        "description": "scipy.cluster.vq",
        "isExtraImport": true,
        "detail": "scipy.cluster.vq",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "save_image",
        "importPath": "torchvision.utils",
        "description": "torchvision.utils",
        "isExtraImport": true,
        "detail": "torchvision.utils",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "fitness",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "butter",
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "isExtraImport": true,
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "filtfilt",
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "isExtraImport": true,
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "torch.backends.cudnn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.backends.cudnn",
        "description": "torch.backends.cudnn",
        "detail": "torch.backends.cudnn",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "optimize_for_mobile",
        "importPath": "torch.utils.mobile_optimizer",
        "description": "torch.utils.mobile_optimizer",
        "isExtraImport": true,
        "detail": "torch.utils.mobile_optimizer",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "models",
        "description": "models",
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "Hardswish",
        "importPath": "utils.activations",
        "description": "utils.activations",
        "isExtraImport": true,
        "detail": "utils.activations",
        "documentation": {}
    },
    {
        "label": "SiLU",
        "importPath": "utils.activations",
        "description": "utils.activations",
        "isExtraImport": true,
        "detail": "utils.activations",
        "documentation": {}
    },
    {
        "label": "RegisterNMS",
        "importPath": "utils.add_nms",
        "description": "utils.add_nms",
        "isExtraImport": true,
        "detail": "utils.add_nms",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "torch.optim.lr_scheduler",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "test",
        "description": "test",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "importPath": "utils.wandb_logging.wandb_utils",
        "description": "utils.wandb_logging.wandb_utils",
        "isExtraImport": true,
        "detail": "utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "check_wandb_resume",
        "importPath": "utils.wandb_logging.wandb_utils",
        "description": "utils.wandb_logging.wandb_utils",
        "isExtraImport": true,
        "detail": "utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "importPath": "utils.wandb_logging.wandb_utils",
        "description": "utils.wandb_logging.wandb_utils",
        "isExtraImport": true,
        "detail": "utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "check_wandb_resume",
        "importPath": "utils.wandb_logging.wandb_utils",
        "description": "utils.wandb_logging.wandb_utils",
        "isExtraImport": true,
        "detail": "utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "sys,os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys.os",
        "description": "sys.os",
        "detail": "sys.os",
        "documentation": {}
    },
    {
        "label": "TrainPipeline",
        "importPath": "isd.pipeline.training_pipeline",
        "description": "isd.pipeline.training_pipeline",
        "isExtraImport": true,
        "detail": "isd.pipeline.training_pipeline",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "cross_origin",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "DataIngestion",
        "kind": 6,
        "importPath": "isd.components.data_ingestion",
        "description": "isd.components.data_ingestion",
        "peekOfCode": "class DataIngestion:\n    def __init__(self, data_ingestion_config: DataIngestionConfig = DataIngestionConfig()):\n        try:\n            self.data_ingestion_config = data_ingestion_config\n            self.s3 = S3Operation()\n        except Exception as e:\n           raise isdException(e, sys)\n    def download_data(self)-> str:\n        '''\n        Fetch data from s3",
        "detail": "isd.components.data_ingestion",
        "documentation": {}
    },
    {
        "label": "DataValidation",
        "kind": 6,
        "importPath": "isd.components.data_validation",
        "description": "isd.components.data_validation",
        "peekOfCode": "class DataValidation:\n    def __init__(\n        self,\n        data_ingestion_artifact: DataIngestionArtifact,\n        data_validation_config: DataValidationConfig,\n    ):\n        try:\n            self.data_ingestion_artifact = data_ingestion_artifact\n            self.data_validation_config = data_validation_config\n        except Exception as e:",
        "detail": "isd.components.data_validation",
        "documentation": {}
    },
    {
        "label": "ModelPusher",
        "kind": 6,
        "importPath": "isd.components.model_pusher",
        "description": "isd.components.model_pusher",
        "peekOfCode": "class ModelPusher:\n    def __init__(self,model_pusher_config: ModelPusherConfig,model_trainer_artifact: ModelTrainerArtifact, s3: S3Operation):\n        self.model_pusher_config = model_pusher_config\n        self.model_trainer_artifacts = model_trainer_artifact\n        self.s3 = s3\n    def initiate_model_pusher(self) -> ModelPusherArtifacts:\n        \"\"\"\n        Method Name :   initiate_model_pusher\n        Description :   This method initiates model pusher. \n        Output      :    Model pusher artifact ",
        "detail": "isd.components.model_pusher",
        "documentation": {}
    },
    {
        "label": "ModelTrainer",
        "kind": 6,
        "importPath": "isd.components.model_trainer",
        "description": "isd.components.model_trainer",
        "peekOfCode": "class ModelTrainer:\n    def __init__(\n        self,\n        model_trainer_config: ModelTrainerConfig,\n    ):\n        self.model_trainer_config = model_trainer_config\n    def initiate_model_trainer(self,) -> ModelTrainerArtifact:\n        logging.info(\"Entered initiate_model_trainer method of ModelTrainer class\")\n        try: \n            logging.info(\"Unzipping data\")",
        "detail": "isd.components.model_trainer",
        "documentation": {}
    },
    {
        "label": "S3Operation",
        "kind": 6,
        "importPath": "isd.configuration.s3_operations",
        "description": "isd.configuration.s3_operations",
        "peekOfCode": "class S3Operation:\n    def __init__(self):\n        self.s3_client = boto3.client(\"s3\")\n        self.s3_resource = boto3.resource(\"s3\")\n    def download_object(self,key, bucket_name, filename):\n        bucket = self.s3_resource.Bucket(bucket_name)\n        bucket.download_file(Key = key, Filename = filename)\n    @staticmethod\n    def read_object(\n        object_name: str, decode: bool = True, make_readable: bool = False",
        "detail": "isd.configuration.s3_operations",
        "documentation": {}
    },
    {
        "label": "DataIngestionArtifact",
        "kind": 6,
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "peekOfCode": "class DataIngestionArtifact:\n    data_zip_file_path:str\n    feature_store_path:str\n@dataclass\nclass DataValidationArtifact:\n    validation_status: bool\n@dataclass\nclass ModelTrainerArtifact:\n    trained_model_file_path: str",
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "DataValidationArtifact",
        "kind": 6,
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "peekOfCode": "class DataValidationArtifact:\n    validation_status: bool\n@dataclass\nclass ModelTrainerArtifact:\n    trained_model_file_path: str\n@dataclass\nclass ModelPusherArtifacts:\n    bucket_name: str\n    s3_model_path: str",
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerArtifact",
        "kind": 6,
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "peekOfCode": "class ModelTrainerArtifact:\n    trained_model_file_path: str\n@dataclass\nclass ModelPusherArtifacts:\n    bucket_name: str\n    s3_model_path: str",
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "ModelPusherArtifacts",
        "kind": 6,
        "importPath": "isd.entity.artifacts_entity",
        "description": "isd.entity.artifacts_entity",
        "peekOfCode": "class ModelPusherArtifacts:\n    bucket_name: str\n    s3_model_path: str",
        "detail": "isd.entity.artifacts_entity",
        "documentation": {}
    },
    {
        "label": "TrainingPipelineConfig",
        "kind": 6,
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "peekOfCode": "class TrainingPipelineConfig:\n    artifacts_dir: str = os.path.join(ARTIFACTS_DIR,TIMESTAMP)\ntraining_pipeline_config:TrainingPipelineConfig = TrainingPipelineConfig() \n@dataclass\nclass DataIngestionConfig:\n    data_ingestion_dir: str = os.path.join(\n        training_pipeline_config.artifacts_dir, DATA_INGESTION_DIR_NAME\n    )\n    feature_store_file_path: str = os.path.join(\n        data_ingestion_dir, DATA_INGESTION_FEATURE_STORE_DIR",
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "DataIngestionConfig",
        "kind": 6,
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "peekOfCode": "class DataIngestionConfig:\n    data_ingestion_dir: str = os.path.join(\n        training_pipeline_config.artifacts_dir, DATA_INGESTION_DIR_NAME\n    )\n    feature_store_file_path: str = os.path.join(\n        data_ingestion_dir, DATA_INGESTION_FEATURE_STORE_DIR\n    )\n    S3_DATA_NAME = DATA_INGESTION_S3_DATA_NAME\n@dataclass\nclass DataValidationConfig:",
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "DataValidationConfig",
        "kind": 6,
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "peekOfCode": "class DataValidationConfig:\n    data_validation_dir: str = os.path.join(\n        training_pipeline_config.artifacts_dir, DATA_VALIDATION_DIR_NAME\n    )\n    valid_status_file_dir: str = os.path.join(data_validation_dir, DATA_VALIDATION_STATUS_FILE)\n    required_file_list = DATA_VALIDATION_ALL_REQUIRED_FILES\n@dataclass\nclass ModelTrainerConfig:\n    model_trainer_dir: str = os.path.join(\n        training_pipeline_config.artifacts_dir, MODEL_TRAINER_DIR_NAME",
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "ModelTrainerConfig",
        "kind": 6,
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "peekOfCode": "class ModelTrainerConfig:\n    model_trainer_dir: str = os.path.join(\n        training_pipeline_config.artifacts_dir, MODEL_TRAINER_DIR_NAME\n    )\n    weight_name = MODEL_TRAINER_PRETRAINED_WEIGHT_URL\n    no_epochs = MODEL_TRAINER_NO_EPOCHS\n    batch_size = MODEL_TRAINER_BATCH_SIZE\n@dataclass\nclass ModelPusherConfig:\n    MODEL_BUCKET_NAME: str = MODEL_BUCKET_NAME",
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "ModelPusherConfig",
        "kind": 6,
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "peekOfCode": "class ModelPusherConfig:\n    MODEL_BUCKET_NAME: str = MODEL_BUCKET_NAME\n    S3_MODEL_KEY_PATH: str = S3_MODEL_NAME",
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "training_pipeline_config:TrainingPipelineConfig",
        "kind": 5,
        "importPath": "isd.entity.config_entity",
        "description": "isd.entity.config_entity",
        "peekOfCode": "training_pipeline_config:TrainingPipelineConfig = TrainingPipelineConfig() \n@dataclass\nclass DataIngestionConfig:\n    data_ingestion_dir: str = os.path.join(\n        training_pipeline_config.artifacts_dir, DATA_INGESTION_DIR_NAME\n    )\n    feature_store_file_path: str = os.path.join(\n        data_ingestion_dir, DATA_INGESTION_FEATURE_STORE_DIR\n    )\n    S3_DATA_NAME = DATA_INGESTION_S3_DATA_NAME",
        "detail": "isd.entity.config_entity",
        "documentation": {}
    },
    {
        "label": "TrainPipeline",
        "kind": 6,
        "importPath": "isd.pipeline.training_pipeline",
        "description": "isd.pipeline.training_pipeline",
        "peekOfCode": "class TrainPipeline:\n    def __init__(self):\n        self.data_ingestion_config = DataIngestionConfig()\n        self.data_validation_config = DataValidationConfig()\n        self.model_trainer_config = ModelTrainerConfig()\n        self.model_pusher_config = ModelPusherConfig()\n        self.s3_operations = S3Operation()\n    def start_data_ingestion(self)-> DataIngestionArtifact:\n        try: \n            logging.info(",
        "detail": "isd.pipeline.training_pipeline",
        "documentation": {}
    },
    {
        "label": "read_yaml_file",
        "kind": 2,
        "importPath": "isd.utils.main_utils",
        "description": "isd.utils.main_utils",
        "peekOfCode": "def read_yaml_file(file_path: str) -> dict:\n    try:\n        with open(file_path, \"rb\") as yaml_file:\n            logging.info(\"Read yaml file successfully\")\n            return yaml.safe_load(yaml_file)\n    except Exception as e:\n        raise isdException(e, sys) from e\ndef decodeImage(imgstring, fileName):\n    imgdata = base64.b64decode(imgstring)\n    with open(\"./data/\" + fileName, 'wb') as f:",
        "detail": "isd.utils.main_utils",
        "documentation": {}
    },
    {
        "label": "decodeImage",
        "kind": 2,
        "importPath": "isd.utils.main_utils",
        "description": "isd.utils.main_utils",
        "peekOfCode": "def decodeImage(imgstring, fileName):\n    imgdata = base64.b64decode(imgstring)\n    with open(\"./data/\" + fileName, 'wb') as f:\n        f.write(imgdata)\n        f.close()\ndef encodeImageIntoBase64(croppedImagePath):\n    with open(croppedImagePath, \"rb\") as f:\n        return base64.b64encode(f.read())",
        "detail": "isd.utils.main_utils",
        "documentation": {}
    },
    {
        "label": "encodeImageIntoBase64",
        "kind": 2,
        "importPath": "isd.utils.main_utils",
        "description": "isd.utils.main_utils",
        "peekOfCode": "def encodeImageIntoBase64(croppedImagePath):\n    with open(croppedImagePath, \"rb\") as f:\n        return base64.b64encode(f.read())",
        "detail": "isd.utils.main_utils",
        "documentation": {}
    },
    {
        "label": "BoundingBox",
        "kind": 6,
        "importPath": "yolov7.deploy.triton-inference-server.boundingbox",
        "description": "yolov7.deploy.triton-inference-server.boundingbox",
        "peekOfCode": "class BoundingBox:\n    def __init__(self, classID, confidence, x1, x2, y1, y2, image_width, image_height):\n        self.classID = classID\n        self.confidence = confidence\n        self.x1 = x1\n        self.x2 = x2\n        self.y1 = y1\n        self.y2 = y2\n        self.u1 = x1 / image_width\n        self.u2 = x2 / image_width",
        "detail": "yolov7.deploy.triton-inference-server.boundingbox",
        "documentation": {}
    },
    {
        "label": "INPUT_NAMES",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.client",
        "description": "yolov7.deploy.triton-inference-server.client",
        "peekOfCode": "INPUT_NAMES = [\"images\"]\nOUTPUT_NAMES = [\"num_dets\", \"det_boxes\", \"det_scores\", \"det_classes\"]\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('mode',\n                        choices=['dummy', 'image', 'video'],\n                        default='dummy',\n                        help='Run mode. \\'dummy\\' will send an emtpy buffer to the server to test if inference works. \\'image\\' will process an image. \\'video\\' will process a video.')\n    parser.add_argument('input',\n                        type=str,",
        "detail": "yolov7.deploy.triton-inference-server.client",
        "documentation": {}
    },
    {
        "label": "OUTPUT_NAMES",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.client",
        "description": "yolov7.deploy.triton-inference-server.client",
        "peekOfCode": "OUTPUT_NAMES = [\"num_dets\", \"det_boxes\", \"det_scores\", \"det_classes\"]\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('mode',\n                        choices=['dummy', 'image', 'video'],\n                        default='dummy',\n                        help='Run mode. \\'dummy\\' will send an emtpy buffer to the server to test if inference works. \\'image\\' will process an image. \\'video\\' will process a video.')\n    parser.add_argument('input',\n                        type=str,\n                        nargs='?',",
        "detail": "yolov7.deploy.triton-inference-server.client",
        "documentation": {}
    },
    {
        "label": "COCOLabels",
        "kind": 6,
        "importPath": "yolov7.deploy.triton-inference-server.labels",
        "description": "yolov7.deploy.triton-inference-server.labels",
        "peekOfCode": "class COCOLabels(Enum):\n    PERSON = 0\n    BICYCLE = 1\n    CAR = 2\n    MOTORBIKE = 3\n    AEROPLANE = 4\n    BUS = 5\n    TRAIN = 6\n    TRUCK = 7\n    BOAT = 8",
        "detail": "yolov7.deploy.triton-inference-server.labels",
        "documentation": {}
    },
    {
        "label": "preprocess",
        "kind": 2,
        "importPath": "yolov7.deploy.triton-inference-server.processing",
        "description": "yolov7.deploy.triton-inference-server.processing",
        "peekOfCode": "def preprocess(img, input_shape, letter_box=True):\n    if letter_box:\n        img_h, img_w, _ = img.shape\n        new_h, new_w = input_shape[0], input_shape[1]\n        offset_h, offset_w = 0, 0\n        if (new_w / img_w) <= (new_h / img_h):\n            new_h = int(img_h * new_w / img_w)\n            offset_h = (input_shape[0] - new_h) // 2\n        else:\n            new_w = int(img_w * new_h / img_h)",
        "detail": "yolov7.deploy.triton-inference-server.processing",
        "documentation": {}
    },
    {
        "label": "postprocess",
        "kind": 2,
        "importPath": "yolov7.deploy.triton-inference-server.processing",
        "description": "yolov7.deploy.triton-inference-server.processing",
        "peekOfCode": "def postprocess(num_dets, det_boxes, det_scores, det_classes, img_w, img_h, input_shape, letter_box=True):\n    boxes = det_boxes[0, :num_dets[0][0]] / np.array([input_shape[0], input_shape[1], input_shape[0], input_shape[1]], dtype=np.float32)\n    scores = det_scores[0, :num_dets[0][0]]\n    classes = det_classes[0, :num_dets[0][0]].astype(np.int)\n    old_h, old_w = img_h, img_w\n    offset_h, offset_w = 0, 0\n    if letter_box:\n        if (img_w / input_shape[1]) >= (img_h / input_shape[0]):\n            old_h = int(input_shape[0] * img_w / input_shape[1])\n            offset_h = (old_h - img_h) // 2",
        "detail": "yolov7.deploy.triton-inference-server.processing",
        "documentation": {}
    },
    {
        "label": "render_box",
        "kind": 2,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "def render_box(img, box, color=(200, 200, 200)):\n    \"\"\"\n    Render a box. Calculates scaling and thickness automatically.\n    :param img: image to render into\n    :param box: (x1, y1, x2, y2) - box coordinates\n    :param color: (b, g, r) - box color\n    :return: updated image\n    \"\"\"\n    x1, y1, x2, y2 = box\n    thickness = int(",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "render_filled_box",
        "kind": 2,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "def render_filled_box(img, box, color=(200, 200, 200)):\n    \"\"\"\n    Render a box. Calculates scaling and thickness automatically.\n    :param img: image to render into\n    :param box: (x1, y1, x2, y2) - box coordinates\n    :param color: (b, g, r) - box color\n    :return: updated image\n    \"\"\"\n    x1, y1, x2, y2 = box\n    img = cv2.rectangle(",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "get_text_size",
        "kind": 2,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "def get_text_size(img, text, normalised_scaling=1.0):\n    \"\"\"\n    Get calculated text size (as box width and height)\n    :param img: image reference, used to determine appropriate text scaling\n    :param text: text to display\n    :param normalised_scaling: additional normalised scaling. Default 1.0.\n    :return: (width, height) - width and height of text box\n    \"\"\"\n    thickness = int(\n        round(",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "render_text",
        "kind": 2,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "def render_text(img, text, pos, color=(200, 200, 200), normalised_scaling=1.0):\n    \"\"\"\n    Render a text into the image. Calculates scaling and thickness automatically.\n    :param img: image to render into\n    :param text: text to display\n    :param pos: (x, y) - upper left coordinates of render position\n    :param color: (b, g, r) - text color\n    :param normalised_scaling: additional normalised scaling. Default 1.0.\n    :return: updated image\n    \"\"\"",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "_LINE_THICKNESS_SCALING",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "_LINE_THICKNESS_SCALING = 500.0\nnp.random.seed(0)\nRAND_COLORS = np.random.randint(50, 255, (64, 3), \"int\")  # used for class visu\nRAND_COLORS[0] = [220, 220, 220]\ndef render_box(img, box, color=(200, 200, 200)):\n    \"\"\"\n    Render a box. Calculates scaling and thickness automatically.\n    :param img: image to render into\n    :param box: (x1, y1, x2, y2) - box coordinates\n    :param color: (b, g, r) - box color",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "RAND_COLORS",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "RAND_COLORS = np.random.randint(50, 255, (64, 3), \"int\")  # used for class visu\nRAND_COLORS[0] = [220, 220, 220]\ndef render_box(img, box, color=(200, 200, 200)):\n    \"\"\"\n    Render a box. Calculates scaling and thickness automatically.\n    :param img: image to render into\n    :param box: (x1, y1, x2, y2) - box coordinates\n    :param color: (b, g, r) - box color\n    :return: updated image\n    \"\"\"",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "RAND_COLORS[0]",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "RAND_COLORS[0] = [220, 220, 220]\ndef render_box(img, box, color=(200, 200, 200)):\n    \"\"\"\n    Render a box. Calculates scaling and thickness automatically.\n    :param img: image to render into\n    :param box: (x1, y1, x2, y2) - box coordinates\n    :param color: (b, g, r) - box color\n    :return: updated image\n    \"\"\"\n    x1, y1, x2, y2 = box",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "_TEXT_THICKNESS_SCALING",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "_TEXT_THICKNESS_SCALING = 700.0\n_TEXT_SCALING = 520.0\ndef get_text_size(img, text, normalised_scaling=1.0):\n    \"\"\"\n    Get calculated text size (as box width and height)\n    :param img: image reference, used to determine appropriate text scaling\n    :param text: text to display\n    :param normalised_scaling: additional normalised scaling. Default 1.0.\n    :return: (width, height) - width and height of text box\n    \"\"\"",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "_TEXT_SCALING",
        "kind": 5,
        "importPath": "yolov7.deploy.triton-inference-server.render",
        "description": "yolov7.deploy.triton-inference-server.render",
        "peekOfCode": "_TEXT_SCALING = 520.0\ndef get_text_size(img, text, normalised_scaling=1.0):\n    \"\"\"\n    Get calculated text size (as box width and height)\n    :param img: image reference, used to determine appropriate text scaling\n    :param text: text to display\n    :param normalised_scaling: additional normalised scaling. Default 1.0.\n    :return: (width, height) - width and height of text box\n    \"\"\"\n    thickness = int(",
        "detail": "yolov7.deploy.triton-inference-server.render",
        "documentation": {}
    },
    {
        "label": "MP",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class MP(nn.Module):\n    def __init__(self, k=2):\n        super(MP, self).__init__()\n        self.m = nn.MaxPool2d(kernel_size=k, stride=k)\n    def forward(self, x):\n        return self.m(x)\nclass SP(nn.Module):\n    def __init__(self, k=3, s=1):\n        super(SP, self).__init__()\n        self.m = nn.MaxPool2d(kernel_size=k, stride=s, padding=k // 2)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SP",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SP(nn.Module):\n    def __init__(self, k=3, s=1):\n        super(SP, self).__init__()\n        self.m = nn.MaxPool2d(kernel_size=k, stride=s, padding=k // 2)\n    def forward(self, x):\n        return self.m(x)\nclass ReOrg(nn.Module):\n    def __init__(self):\n        super(ReOrg, self).__init__()\n    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ReOrg",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ReOrg(nn.Module):\n    def __init__(self):\n        super(ReOrg, self).__init__()\n    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)\n        return torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1)\nclass Concat(nn.Module):\n    def __init__(self, dimension=1):\n        super(Concat, self).__init__()\n        self.d = dimension\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Concat",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Concat(nn.Module):\n    def __init__(self, dimension=1):\n        super(Concat, self).__init__()\n        self.d = dimension\n    def forward(self, x):\n        return torch.cat(x, self.d)\nclass Chuncat(nn.Module):\n    def __init__(self, dimension=1):\n        super(Chuncat, self).__init__()\n        self.d = dimension",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Chuncat",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Chuncat(nn.Module):\n    def __init__(self, dimension=1):\n        super(Chuncat, self).__init__()\n        self.d = dimension\n    def forward(self, x):\n        x1 = []\n        x2 = []\n        for xi in x:\n            xi1, xi2 = xi.chunk(2, self.d)\n            x1.append(xi1)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Shortcut",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Shortcut(nn.Module):\n    def __init__(self, dimension=0):\n        super(Shortcut, self).__init__()\n        self.d = dimension\n    def forward(self, x):\n        return x[0]+x[1]\nclass Foldcut(nn.Module):\n    def __init__(self, dimension=0):\n        super(Foldcut, self).__init__()\n        self.d = dimension",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Foldcut",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Foldcut(nn.Module):\n    def __init__(self, dimension=0):\n        super(Foldcut, self).__init__()\n        self.d = dimension\n    def forward(self, x):\n        x1, x2 = x.chunk(2, self.d)\n        return x1+x2\nclass Conv(nn.Module):\n    # Standard convolution\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Conv",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Conv(nn.Module):\n    # Standard convolution\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n    def fuseforward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RobustConv",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RobustConv(nn.Module):\n    # Robust convolution (use high kernel size 7-11 for: downsampling and other layers). Train for 300 - 450 epochs.\n    def __init__(self, c1, c2, k=7, s=1, p=None, g=1, act=True, layer_scale_init_value=1e-6):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(RobustConv, self).__init__()\n        self.conv_dw = Conv(c1, c1, k=k, s=s, p=p, g=c1, act=act)\n        self.conv1x1 = nn.Conv2d(c1, c2, 1, 1, 0, groups=1, bias=True)\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones(c2)) if layer_scale_init_value > 0 else None\n    def forward(self, x):\n        x = x.to(memory_format=torch.channels_last)\n        x = self.conv1x1(self.conv_dw(x))",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RobustConv2",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RobustConv2(nn.Module):\n    # Robust convolution 2 (use [32, 5, 2] or [32, 7, 4] or [32, 11, 8] for one of the paths in CSP).\n    def __init__(self, c1, c2, k=7, s=4, p=None, g=1, act=True, layer_scale_init_value=1e-6):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(RobustConv2, self).__init__()\n        self.conv_strided = Conv(c1, c1, k=k, s=s, p=p, g=c1, act=act)\n        self.conv_deconv = nn.ConvTranspose2d(in_channels=c1, out_channels=c2, kernel_size=s, stride=s, \n                                              padding=0, bias=True, dilation=1, groups=1\n        )\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones(c2)) if layer_scale_init_value > 0 else None\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class GhostConv(nn.Module):\n    # Ghost Convolution https://github.com/huawei-noah/ghostnet\n    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups\n        super(GhostConv, self).__init__()\n        c_ = c2 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, k, s, None, g, act)\n        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act)\n    def forward(self, x):\n        y = self.cv1(x)\n        return torch.cat([y, self.cv2(y)], 1)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Stem",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Stem(nn.Module):\n    # Stem\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(Stem, self).__init__()\n        c_ = int(c2/2)  # hidden channels\n        self.cv1 = Conv(c1, c_, 3, 2)\n        self.cv2 = Conv(c_, c_, 1, 1)\n        self.cv3 = Conv(c_, c_, 3, 2)\n        self.pool = torch.nn.MaxPool2d(2, stride=2)\n        self.cv4 = Conv(2 * c_, c2, 1, 1)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "DownC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class DownC(nn.Module):\n    # Spatial pyramid pooling layer used in YOLOv3-SPP\n    def __init__(self, c1, c2, n=1, k=2):\n        super(DownC, self).__init__()\n        c_ = int(c1)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c2//2, 3, k)\n        self.cv3 = Conv(c1, c2//2, 1, 1)\n        self.mp = nn.MaxPool2d(kernel_size=k, stride=k)\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SPP",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SPP(nn.Module):\n    # Spatial pyramid pooling layer used in YOLOv3-SPP\n    def __init__(self, c1, c2, k=(5, 9, 13)):\n        super(SPP, self).__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)\n        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])\n    def forward(self, x):\n        x = self.cv1(x)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Bottleneck(nn.Module):\n    # Darknet bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super(Bottleneck, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c2, 3, 1, g=g)\n        self.add = shortcut and c1 == c2\n    def forward(self, x):\n        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Res",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Res(nn.Module):\n    # ResNet bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super(Res, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c_, 3, 1, g=g)\n        self.cv3 = Conv(c_, c2, 1, 1)\n        self.add = shortcut and c1 == c2\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResX",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResX(Res):\n    # ResNet bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super().__init__(c1, c2, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\nclass Ghost(nn.Module):\n    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet\n    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride\n        super(Ghost, self).__init__()\n        c_ = c2 // 2",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Ghost",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Ghost(nn.Module):\n    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet\n    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride\n        super(Ghost, self).__init__()\n        c_ = c2 // 2\n        self.conv = nn.Sequential(GhostConv(c1, c_, 1, 1),  # pw\n                                  DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw\n                                  GhostConv(c_, c2, 1, 1, act=False))  # pw-linear\n        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False),\n                                      Conv(c1, c2, 1, 1, act=False)) if s == 2 else nn.Identity()",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SPPCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SPPCSPC(nn.Module):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, k=(5, 9, 13)):\n        super(SPPCSPC, self).__init__()\n        c_ = int(2 * c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(c_, c_, 3, 1)\n        self.cv4 = Conv(c_, c_, 1, 1)\n        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "GhostSPPCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class GhostSPPCSPC(SPPCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, k=(5, 9, 13)):\n        super().__init__(c1, c2, n, shortcut, g, e, k)\n        c_ = int(2 * c2 * e)  # hidden channels\n        self.cv1 = GhostConv(c1, c_, 1, 1)\n        self.cv2 = GhostConv(c1, c_, 1, 1)\n        self.cv3 = GhostConv(c_, c_, 3, 1)\n        self.cv4 = GhostConv(c_, c_, 1, 1)\n        self.cv5 = GhostConv(4 * c_, c_, 1, 1)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "GhostStem",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class GhostStem(Stem):\n    # Stem\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super().__init__(c1, c2, k, s, p, g, act)\n        c_ = int(c2/2)  # hidden channels\n        self.cv1 = GhostConv(c1, c_, 3, 2)\n        self.cv2 = GhostConv(c_, c_, 1, 1)\n        self.cv3 = GhostConv(c_, c_, 3, 2)\n        self.cv4 = GhostConv(2 * c_, c2, 1, 1)\nclass BottleneckCSPA(nn.Module):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "BottleneckCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class BottleneckCSPA(nn.Module):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(BottleneckCSPA, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1, 1)\n        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "BottleneckCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class BottleneckCSPB(nn.Module):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(BottleneckCSPB, self).__init__()\n        c_ = int(c2)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1, 1)\n        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "BottleneckCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class BottleneckCSPC(nn.Module):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(BottleneckCSPC, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(c_, c_, 1, 1)\n        self.cv4 = Conv(2 * c_, c2, 1, 1)\n        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResCSPA(BottleneckCSPA):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[Res(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass ResCSPB(BottleneckCSPB):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResCSPB(BottleneckCSPB):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2)  # hidden channels\n        self.m = nn.Sequential(*[Res(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass ResCSPC(BottleneckCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResCSPC(BottleneckCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[Res(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass ResXCSPA(ResCSPA):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResXCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResXCSPA(ResCSPA):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[Res(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\nclass ResXCSPB(ResCSPB):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResXCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResXCSPB(ResCSPB):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2)  # hidden channels\n        self.m = nn.Sequential(*[Res(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\nclass ResXCSPC(ResCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ResXCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ResXCSPC(ResCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[Res(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\nclass GhostCSPA(BottleneckCSPA):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "GhostCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class GhostCSPA(BottleneckCSPA):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[Ghost(c_, c_) for _ in range(n)])\nclass GhostCSPB(BottleneckCSPB):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "GhostCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class GhostCSPB(BottleneckCSPB):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2)  # hidden channels\n        self.m = nn.Sequential(*[Ghost(c_, c_) for _ in range(n)])\nclass GhostCSPC(BottleneckCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "GhostCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class GhostCSPC(BottleneckCSPC):\n    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[Ghost(c_, c_) for _ in range(n)])\n##### end of cspnet #####\n##### yolor #####\nclass ImplicitA(nn.Module):\n    def __init__(self, channel, mean=0., std=.02):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ImplicitA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ImplicitA(nn.Module):\n    def __init__(self, channel, mean=0., std=.02):\n        super(ImplicitA, self).__init__()\n        self.channel = channel\n        self.mean = mean\n        self.std = std\n        self.implicit = nn.Parameter(torch.zeros(1, channel, 1, 1))\n        nn.init.normal_(self.implicit, mean=self.mean, std=self.std)\n    def forward(self, x):\n        return self.implicit + x",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ImplicitM",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ImplicitM(nn.Module):\n    def __init__(self, channel, mean=1., std=.02):\n        super(ImplicitM, self).__init__()\n        self.channel = channel\n        self.mean = mean\n        self.std = std\n        self.implicit = nn.Parameter(torch.ones(1, channel, 1, 1))\n        nn.init.normal_(self.implicit, mean=self.mean, std=self.std)\n    def forward(self, x):\n        return self.implicit * x",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepConv",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepConv(nn.Module):\n    # Represented convolution\n    # https://arxiv.org/abs/2101.03697\n    def __init__(self, c1, c2, k=3, s=1, p=None, g=1, act=True, deploy=False):\n        super(RepConv, self).__init__()\n        self.deploy = deploy\n        self.groups = g\n        self.in_channels = c1\n        self.out_channels = c2\n        assert k == 3",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepBottleneck",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepBottleneck(Bottleneck):\n    # Standard bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super().__init__(c1, c2, shortcut=True, g=1, e=0.5)\n        c_ = int(c2 * e)  # hidden channels\n        self.cv2 = RepConv(c_, c2, 3, 1, g=g)\nclass RepBottleneckCSPA(BottleneckCSPA):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepBottleneckCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepBottleneckCSPA(BottleneckCSPA):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[RepBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\nclass RepBottleneckCSPB(BottleneckCSPB):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepBottleneckCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepBottleneckCSPB(BottleneckCSPB):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2)  # hidden channels\n        self.m = nn.Sequential(*[RepBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\nclass RepBottleneckCSPC(BottleneckCSPC):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepBottleneckCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepBottleneckCSPC(BottleneckCSPC):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[RepBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\nclass RepRes(Res):\n    # Standard bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super().__init__(c1, c2, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepRes",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepRes(Res):\n    # Standard bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super().__init__(c1, c2, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.cv2 = RepConv(c_, c_, 3, 1, g=g)\nclass RepResCSPA(ResCSPA):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResCSPA(ResCSPA):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[RepRes(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass RepResCSPB(ResCSPB):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResCSPB(ResCSPB):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2)  # hidden channels\n        self.m = nn.Sequential(*[RepRes(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass RepResCSPC(ResCSPC):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResCSPC(ResCSPC):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[RepRes(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass RepResX(ResX):\n    # Standard bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super().__init__(c1, c2, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResX",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResX(ResX):\n    # Standard bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n        super().__init__(c1, c2, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.cv2 = RepConv(c_, c_, 3, 1, g=g)\nclass RepResXCSPA(ResXCSPA):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResXCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResXCSPA(ResXCSPA):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[RepResX(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass RepResXCSPB(ResXCSPB):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResXCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResXCSPB(ResXCSPB):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2)  # hidden channels\n        self.m = nn.Sequential(*[RepResX(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\nclass RepResXCSPC(ResXCSPC):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepResXCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepResXCSPC(ResXCSPC):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*[RepResX(c_, c_, shortcut, g, e=0.5) for _ in range(n)])\n##### end of repvgg #####\n##### transformer #####\nclass TransformerLayer(nn.Module):\n    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "TransformerLayer",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class TransformerLayer(nn.Module):\n    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)\n    def __init__(self, c, num_heads):\n        super().__init__()\n        self.q = nn.Linear(c, c, bias=False)\n        self.k = nn.Linear(c, c, bias=False)\n        self.v = nn.Linear(c, c, bias=False)\n        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)\n        self.fc1 = nn.Linear(c, c, bias=False)\n        self.fc2 = nn.Linear(c, c, bias=False)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "TransformerBlock",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class TransformerBlock(nn.Module):\n    # Vision Transformer https://arxiv.org/abs/2010.11929\n    def __init__(self, c1, c2, num_heads, num_layers):\n        super().__init__()\n        self.conv = None\n        if c1 != c2:\n            self.conv = Conv(c1, c2)\n        self.linear = nn.Linear(c2, c2)  # learnable position embedding\n        self.tr = nn.Sequential(*[TransformerLayer(c2, num_heads) for _ in range(num_layers)])\n        self.c2 = c2",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Focus",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Focus(nn.Module):\n    # Focus wh information into c-space\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(Focus, self).__init__()\n        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)\n        # self.contract = Contract(gain=2)\n    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)\n        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))\n        # return self.conv(self.contract(x))\nclass SPPF(nn.Module):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SPPF(nn.Module):\n    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher\n    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * 4, c2, 1, 1)\n        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n    def forward(self, x):\n        x = self.cv1(x)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Contract",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Contract(nn.Module):\n    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)\n    def __init__(self, gain=2):\n        super().__init__()\n        self.gain = gain\n    def forward(self, x):\n        N, C, H, W = x.size()  # assert (H / s == 0) and (W / s == 0), 'Indivisible gain'\n        s = self.gain\n        x = x.view(N, C, H // s, s, W // s, s)  # x(1,64,40,2,40,2)\n        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Expand",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Expand(nn.Module):\n    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)\n    def __init__(self, gain=2):\n        super().__init__()\n        self.gain = gain\n    def forward(self, x):\n        N, C, H, W = x.size()  # assert C / s ** 2 == 0, 'Indivisible gain'\n        s = self.gain\n        x = x.view(N, s, s, C // s ** 2, H, W)  # x(1,2,2,16,80,80)\n        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "NMS",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class NMS(nn.Module):\n    # Non-Maximum Suppression (NMS) module\n    conf = 0.25  # confidence threshold\n    iou = 0.45  # IoU threshold\n    classes = None  # (optional list) filter by class\n    def __init__(self):\n        super(NMS, self).__init__()\n    def forward(self, x):\n        return non_max_suppression(x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes)\nclass autoShape(nn.Module):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "autoShape",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class autoShape(nn.Module):\n    # input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS\n    conf = 0.25  # NMS confidence threshold\n    iou = 0.45  # NMS IoU threshold\n    classes = None  # (optional list) filter by class\n    def __init__(self, model):\n        super(autoShape, self).__init__()\n        self.model = model.eval()\n    def autoshape(self):\n        print('autoShape already enabled, skipping... ')  # model already converted to model.autoshape()",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Detections",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Detections:\n    # detections class for YOLOv5 inference results\n    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):\n        super(Detections, self).__init__()\n        d = pred[0].device  # device\n        gn = [torch.tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1., 1.], device=d) for im in imgs]  # normalizations\n        self.imgs = imgs  # list of images as numpy arrays\n        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)\n        self.names = names  # class names\n        self.files = files  # image filenames",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Classify",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Classify(nn.Module):\n    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(Classify, self).__init__()\n        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)\n        self.flat = nn.Flatten()\n    def forward(self, x):\n        z = torch.cat([self.aap(y) for y in (x if isinstance(x, list) else [x])], 1)  # cat if list\n        return self.flat(self.conv(z))  # flatten to x(b,c2)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ConvBN",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ConvBN(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size,\n                             stride=1, padding=0, dilation=1, groups=1, deploy=False, nonlinear=None):\n        super().__init__()\n        if nonlinear is None:\n            self.nonlinear = nn.Identity()\n        else:\n            self.nonlinear = nonlinear\n        if deploy:\n            self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "OREPA_3x3_RepConv",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class OREPA_3x3_RepConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size,\n                 stride=1, padding=0, dilation=1, groups=1,\n                 internal_channels_1x1_3x3=None,\n                 deploy=False, nonlinear=None, single_init=False):\n        super(OREPA_3x3_RepConv, self).__init__()\n        self.deploy = deploy\n        if nonlinear is None:\n            self.nonlinear = nn.Identity()\n        else:",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "RepConv_OREPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class RepConv_OREPA(nn.Module):\n    def __init__(self, c1, c2, k=3, s=1, padding=1, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False, nonlinear=nn.SiLU()):\n        super(RepConv_OREPA, self).__init__()\n        self.deploy = deploy\n        self.groups = groups\n        self.in_channels = c1\n        self.out_channels = c2\n        self.padding = padding\n        self.dilation = dilation\n        self.groups = groups",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "WindowAttention",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class WindowAttention(nn.Module):\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size  # Wh, Ww\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = qk_scale or head_dim ** -0.5\n        # define a parameter table of relative position bias\n        self.relative_position_bias_table = nn.Parameter(",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Mlp",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.SiLU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SwinTransformerLayer",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SwinTransformerLayer(nn.Module):\n    def __init__(self, dim, num_heads, window_size=8, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.SiLU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SwinTransformerBlock",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SwinTransformerBlock(nn.Module):\n    def __init__(self, c1, c2, num_heads, num_layers, window_size=8):\n        super().__init__()\n        self.conv = None\n        if c1 != c2:\n            self.conv = Conv(c1, c2)\n        # remove input_resolution\n        self.blocks = nn.Sequential(*[SwinTransformerLayer(dim=c2, num_heads=num_heads, window_size=window_size,\n                                 shift_size=0 if (i % 2 == 0) else window_size // 2) for i in range(num_layers)])\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "STCSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class STCSPA(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(STCSPA, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1, 1)\n        num_heads = c_ // 32\n        self.m = SwinTransformerBlock(c_, c_, num_heads, n)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "STCSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class STCSPB(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(STCSPB, self).__init__()\n        c_ = int(c2)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1, 1)\n        num_heads = c_ // 32\n        self.m = SwinTransformerBlock(c_, c_, num_heads, n)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "STCSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class STCSPC(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(STCSPC, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(c_, c_, 1, 1)\n        self.cv4 = Conv(2 * c_, c2, 1, 1)\n        num_heads = c_ // 32",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "WindowAttention_v2",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class WindowAttention_v2(nn.Module):\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.,\n                 pretrained_window_size=[0, 0]):\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size  # Wh, Ww\n        self.pretrained_window_size = pretrained_window_size\n        self.num_heads = num_heads\n        self.logit_scale = nn.Parameter(torch.log(10 * torch.ones((num_heads, 1, 1))), requires_grad=True)\n        # mlp to generate continuous relative position bias",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "Mlp_v2",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class Mlp_v2(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.SiLU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SwinTransformerLayer_v2",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SwinTransformerLayer_v2(nn.Module):\n    def __init__(self, dim, num_heads, window_size=7, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.SiLU, norm_layer=nn.LayerNorm, pretrained_window_size=0):\n        super().__init__()\n        self.dim = dim\n        #self.input_resolution = input_resolution\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "SwinTransformer2Block",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class SwinTransformer2Block(nn.Module):\n    def __init__(self, c1, c2, num_heads, num_layers, window_size=7):\n        super().__init__()\n        self.conv = None\n        if c1 != c2:\n            self.conv = Conv(c1, c2)\n        # remove input_resolution\n        self.blocks = nn.Sequential(*[SwinTransformerLayer_v2(dim=c2, num_heads=num_heads, window_size=window_size,\n                                 shift_size=0 if (i % 2 == 0) else window_size // 2) for i in range(num_layers)])\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ST2CSPA",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ST2CSPA(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(ST2CSPA, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1, 1)\n        num_heads = c_ // 32\n        self.m = SwinTransformer2Block(c_, c_, num_heads, n)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ST2CSPB",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ST2CSPB(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(ST2CSPB, self).__init__()\n        c_ = int(c2)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1, 1)\n        num_heads = c_ // 32\n        self.m = SwinTransformer2Block(c_, c_, num_heads, n)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "ST2CSPC",
        "kind": 6,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "class ST2CSPC(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super(ST2CSPC, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(c_, c_, 1, 1)\n        self.cv4 = Conv(2 * c_, c2, 1, 1)\n        num_heads = c_ // 32",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "autopad",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def autopad(k, p=None):  # kernel, padding\n    # Pad to 'same'\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n    return p\nclass MP(nn.Module):\n    def __init__(self, k=2):\n        super(MP, self).__init__()\n        self.m = nn.MaxPool2d(kernel_size=k, stride=k)\n    def forward(self, x):",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def DWConv(c1, c2, k=1, s=1, act=True):\n    # Depthwise convolution\n    return Conv(c1, c2, k, s, g=math.gcd(c1, c2), act=act)\nclass GhostConv(nn.Module):\n    # Ghost Convolution https://github.com/huawei-noah/ghostnet\n    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups\n        super(GhostConv, self).__init__()\n        c_ = c2 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, k, s, None, g, act)\n        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "transI_fusebn",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def transI_fusebn(kernel, bn):\n    gamma = bn.weight\n    std = (bn.running_var + bn.eps).sqrt()\n    return kernel * ((gamma / std).reshape(-1, 1, 1, 1)), bn.bias - bn.running_mean * gamma / std\nclass ConvBN(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size,\n                             stride=1, padding=0, dilation=1, groups=1, deploy=False, nonlinear=None):\n        super().__init__()\n        if nonlinear is None:\n            self.nonlinear = nn.Identity()",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "window_partition",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def window_partition(x, window_size):\n    B, H, W, C = x.shape\n    assert H % window_size == 0, 'feature map h and w can not divide by window size'\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    return windows\ndef window_reverse(windows, window_size, H, W):\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "window_reverse",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def window_reverse(windows, window_size, H, W):\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\nclass SwinTransformerLayer(nn.Module):\n    def __init__(self, dim, num_heads, window_size=8, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.SiLU, norm_layer=nn.LayerNorm):\n        super().__init__()",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "window_partition_v2",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def window_partition_v2(x, window_size):\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    return windows\ndef window_reverse_v2(windows, window_size, H, W):\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "window_reverse_v2",
        "kind": 2,
        "importPath": "yolov7.models.common",
        "description": "yolov7.models.common",
        "peekOfCode": "def window_reverse_v2(windows, window_size, H, W):\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\nclass SwinTransformerLayer_v2(nn.Module):\n    def __init__(self, dim, num_heads, window_size=7, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.SiLU, norm_layer=nn.LayerNorm, pretrained_window_size=0):\n        super().__init__()",
        "detail": "yolov7.models.common",
        "documentation": {}
    },
    {
        "label": "CrossConv",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class CrossConv(nn.Module):\n    # Cross Convolution Downsample\n    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):\n        # ch_in, ch_out, kernel, stride, groups, expansion, shortcut\n        super(CrossConv, self).__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, (1, k), (1, s))\n        self.cv2 = Conv(c_, c2, (k, 1), (s, 1), g=g)\n        self.add = shortcut and c1 == c2\n    def forward(self, x):",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "Sum",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class Sum(nn.Module):\n    # Weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070\n    def __init__(self, n, weight=False):  # n: number of inputs\n        super(Sum, self).__init__()\n        self.weight = weight  # apply weights boolean\n        self.iter = range(n - 1)  # iter object\n        if weight:\n            self.w = nn.Parameter(-torch.arange(1., n) / 2, requires_grad=True)  # layer weights\n    def forward(self, x):\n        y = x[0]  # no weight",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "MixConv2d",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class MixConv2d(nn.Module):\n    # Mixed Depthwise Conv https://arxiv.org/abs/1907.09595\n    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):\n        super(MixConv2d, self).__init__()\n        groups = len(k)\n        if equal_ch:  # equal c_ per group\n            i = torch.linspace(0, groups - 1E-6, c2).floor()  # c2 indices\n            c_ = [(i == g).sum() for g in range(groups)]  # intermediate channels\n        else:  # equal weight.numel() per group\n            b = [c2] + [0] * groups",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "Ensemble",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class Ensemble(nn.ModuleList):\n    # Ensemble of models\n    def __init__(self):\n        super(Ensemble, self).__init__()\n    def forward(self, x, augment=False):\n        y = []\n        for module in self:\n            y.append(module(x, augment)[0])\n        # y = torch.stack(y).max(0)[0]  # max ensemble\n        # y = torch.stack(y).mean(0)  # mean ensemble",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "ORT_NMS",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class ORT_NMS(torch.autograd.Function):\n    '''ONNX-Runtime NMS operation'''\n    @staticmethod\n    def forward(ctx,\n                boxes,\n                scores,\n                max_output_boxes_per_class=torch.tensor([100]),\n                iou_threshold=torch.tensor([0.45]),\n                score_threshold=torch.tensor([0.25])):\n        device = boxes.device",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "TRT_NMS",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class TRT_NMS(torch.autograd.Function):\n    '''TensorRT NMS operation'''\n    @staticmethod\n    def forward(\n        ctx,\n        boxes,\n        scores,\n        background_class=-1,\n        box_coding=1,\n        iou_threshold=0.45,",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "ONNX_ORT",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class ONNX_ORT(nn.Module):\n    '''onnx module with ONNX-Runtime NMS operation.'''\n    def __init__(self, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=640, device=None, n_classes=80):\n        super().__init__()\n        self.device = device if device else torch.device(\"cpu\")\n        self.max_obj = torch.tensor([max_obj]).to(device)\n        self.iou_threshold = torch.tensor([iou_thres]).to(device)\n        self.score_threshold = torch.tensor([score_thres]).to(device)\n        self.max_wh = max_wh # if max_wh != 0 : non-agnostic else : agnostic\n        self.convert_matrix = torch.tensor([[1, 0, 1, 0], [0, 1, 0, 1], [-0.5, 0, 0.5, 0], [0, -0.5, 0, 0.5]],",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "ONNX_TRT",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class ONNX_TRT(nn.Module):\n    '''onnx module with TensorRT NMS operation.'''\n    def __init__(self, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=None ,device=None, n_classes=80):\n        super().__init__()\n        assert max_wh is None\n        self.device = device if device else torch.device('cpu')\n        self.background_class = -1,\n        self.box_coding = 1,\n        self.iou_threshold = iou_thres\n        self.max_obj = max_obj",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "End2End",
        "kind": 6,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "class End2End(nn.Module):\n    '''export onnx or tensorrt model with NMS operation.'''\n    def __init__(self, model, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=None, device=None, n_classes=80):\n        super().__init__()\n        device = device if device else torch.device('cpu')\n        assert isinstance(max_wh,(int)) or max_wh is None\n        self.model = model.to(device)\n        self.model.model[-1].end2end = True\n        self.patch_model = ONNX_TRT if max_wh is None else ONNX_ORT\n        self.end2end = self.patch_model(max_obj, iou_thres, score_thres, max_wh, device, n_classes)",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "kind": 2,
        "importPath": "yolov7.models.experimental",
        "description": "yolov7.models.experimental",
        "peekOfCode": "def attempt_load(weights, map_location=None):\n    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\n    model = Ensemble()\n    for w in weights if isinstance(weights, list) else [weights]:\n        attempt_download(w)\n        ckpt = torch.load(w, map_location=map_location)  # load\n        model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model\n    # Compatibility updates\n    for m in model.modules():\n        if type(m) in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU]:",
        "detail": "yolov7.models.experimental",
        "documentation": {}
    },
    {
        "label": "Detect",
        "kind": 6,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "class Detect(nn.Module):\n    stride = None  # strides computed during build\n    export = False  # onnx export\n    end2end = False\n    include_nms = False\n    concat = False\n    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer\n        super(Detect, self).__init__()\n        self.nc = nc  # number of classes\n        self.no = nc + 5  # number of outputs per anchor",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "IDetect",
        "kind": 6,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "class IDetect(nn.Module):\n    stride = None  # strides computed during build\n    export = False  # onnx export\n    end2end = False\n    include_nms = False\n    concat = False\n    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer\n        super(IDetect, self).__init__()\n        self.nc = nc  # number of classes\n        self.no = nc + 5  # number of outputs per anchor",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "IKeypoint",
        "kind": 6,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "class IKeypoint(nn.Module):\n    stride = None  # strides computed during build\n    export = False  # onnx export\n    def __init__(self, nc=80, anchors=(), nkpt=17, ch=(), inplace=True, dw_conv_kpt=False):  # detection layer\n        super(IKeypoint, self).__init__()\n        self.nc = nc  # number of classes\n        self.nkpt = nkpt\n        self.dw_conv_kpt = dw_conv_kpt\n        self.no_det=(nc + 5)  # number of outputs per anchor for box and class\n        self.no_kpt = 3*self.nkpt ## number of outputs per anchor for keypoints",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "IAuxDetect",
        "kind": 6,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "class IAuxDetect(nn.Module):\n    stride = None  # strides computed during build\n    export = False  # onnx export\n    end2end = False\n    include_nms = False\n    concat = False\n    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer\n        super(IAuxDetect, self).__init__()\n        self.nc = nc  # number of classes\n        self.no = nc + 5  # number of outputs per anchor",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "IBin",
        "kind": 6,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "class IBin(nn.Module):\n    stride = None  # strides computed during build\n    export = False  # onnx export\n    def __init__(self, nc=80, anchors=(), ch=(), bin_count=21):  # detection layer\n        super(IBin, self).__init__()\n        self.nc = nc  # number of classes\n        self.bin_count = bin_count\n        self.w_bin_sigmoid = SigmoidBin(bin_count=self.bin_count, min=0.0, max=4.0)\n        self.h_bin_sigmoid = SigmoidBin(bin_count=self.bin_count, min=0.0, max=4.0)\n        # classes, x,y,obj",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "class Model(nn.Module):\n    def __init__(self, cfg='yolor-csp-c.yaml', ch=3, nc=None, anchors=None):  # model, input channels, number of classes\n        super(Model, self).__init__()\n        self.traced = False\n        if isinstance(cfg, dict):\n            self.yaml = cfg  # model dict\n        else:  # is *.yaml\n            import yaml  # for torch hub\n            self.yaml_file = Path(cfg).name\n            with open(cfg) as f:",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "parse_model",
        "kind": 2,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "def parse_model(d, ch):  # model_dict, input_channels(3)\n    logger.info('\\n%3s%18s%3s%10s  %-40s%-30s' % ('', 'from', 'n', 'params', 'module', 'arguments'))\n    anchors, nc, gd, gw = d['anchors'], d['nc'], d['depth_multiple'], d['width_multiple']\n    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors\n    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)\n    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out\n    for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):  # from, number, module, args\n        m = eval(m) if isinstance(m, str) else m  # eval strings\n        for j, a in enumerate(args):\n            try:",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov7.models.yolo",
        "description": "yolov7.models.yolo",
        "peekOfCode": "logger = logging.getLogger(__name__)\nimport torch\nfrom models.common import *\nfrom models.experimental import *\nfrom utils.autoanchor import check_anchor_order\nfrom utils.general import make_divisible, check_file, set_logging\nfrom utils.torch_utils import time_synchronized, fuse_conv_and_bn, model_info, scale_img, initialize_weights, \\\n    select_device, copy_attr\nfrom utils.loss import SigmoidBin\ntry:",
        "detail": "yolov7.models.yolo",
        "documentation": {}
    },
    {
        "label": "port",
        "kind": 5,
        "importPath": "yolov7.utils.aws.resume",
        "description": "yolov7.utils.aws.resume",
        "peekOfCode": "port = 0  # --master_port\npath = Path('').resolve()\nfor last in path.rglob('*/**/last.pt'):\n    ckpt = torch.load(last)\n    if ckpt['optimizer'] is None:\n        continue\n    # Load opt.yaml\n    with open(last.parent.parent / 'opt.yaml') as f:\n        opt = yaml.load(f, Loader=yaml.SafeLoader)\n    # Get device count",
        "detail": "yolov7.utils.aws.resume",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "yolov7.utils.aws.resume",
        "description": "yolov7.utils.aws.resume",
        "peekOfCode": "path = Path('').resolve()\nfor last in path.rglob('*/**/last.pt'):\n    ckpt = torch.load(last)\n    if ckpt['optimizer'] is None:\n        continue\n    # Load opt.yaml\n    with open(last.parent.parent / 'opt.yaml') as f:\n        opt = yaml.load(f, Loader=yaml.SafeLoader)\n    # Get device count\n    d = opt['device'].split(',')  # devices",
        "detail": "yolov7.utils.aws.resume",
        "documentation": {}
    },
    {
        "label": "create_dataset_artifact",
        "kind": 2,
        "importPath": "yolov7.utils.wandb_logging.log_dataset",
        "description": "yolov7.utils.wandb_logging.log_dataset",
        "peekOfCode": "def create_dataset_artifact(opt):\n    with open(opt.data) as f:\n        data = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n    logger = WandbLogger(opt, '', None, data, job_type='Dataset Creation')\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data', type=str, default='data/coco.yaml', help='data.yaml path')\n    parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n    parser.add_argument('--project', type=str, default='YOLOR', help='name of W&B Project')\n    opt = parser.parse_args()",
        "detail": "yolov7.utils.wandb_logging.log_dataset",
        "documentation": {}
    },
    {
        "label": "WANDB_ARTIFACT_PREFIX",
        "kind": 5,
        "importPath": "yolov7.utils.wandb_logging.log_dataset",
        "description": "yolov7.utils.wandb_logging.log_dataset",
        "peekOfCode": "WANDB_ARTIFACT_PREFIX = 'wandb-artifact://'\ndef create_dataset_artifact(opt):\n    with open(opt.data) as f:\n        data = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n    logger = WandbLogger(opt, '', None, data, job_type='Dataset Creation')\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data', type=str, default='data/coco.yaml', help='data.yaml path')\n    parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n    parser.add_argument('--project', type=str, default='YOLOR', help='name of W&B Project')",
        "detail": "yolov7.utils.wandb_logging.log_dataset",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "kind": 6,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "class WandbLogger():\n    def __init__(self, opt, name, run_id, data_dict, job_type='Training'):\n        # Pre-training routine --\n        self.job_type = job_type\n        self.wandb, self.wandb_run, self.data_dict = wandb, None if not wandb else wandb.run, data_dict\n        # It's more elegant to stick to 1 wandb.init call, but useful config data is overwritten in the WandbLogger's wandb.init call\n        if isinstance(opt.resume, str):  # checks resume from artifact\n            if opt.resume.startswith(WANDB_ARTIFACT_PREFIX):\n                run_id, project, model_artifact_name = get_run_info(opt.resume)\n                model_artifact_name = WANDB_ARTIFACT_PREFIX + model_artifact_name",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "remove_prefix",
        "kind": 2,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "def remove_prefix(from_string, prefix=WANDB_ARTIFACT_PREFIX):\n    return from_string[len(prefix):]\ndef check_wandb_config_file(data_config_file):\n    wandb_config = '_wandb.'.join(data_config_file.rsplit('.', 1))  # updated data.yaml path\n    if Path(wandb_config).is_file():\n        return wandb_config\n    return data_config_file\ndef get_run_info(run_path):\n    run_path = Path(remove_prefix(run_path, WANDB_ARTIFACT_PREFIX))\n    run_id = run_path.stem",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "check_wandb_config_file",
        "kind": 2,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "def check_wandb_config_file(data_config_file):\n    wandb_config = '_wandb.'.join(data_config_file.rsplit('.', 1))  # updated data.yaml path\n    if Path(wandb_config).is_file():\n        return wandb_config\n    return data_config_file\ndef get_run_info(run_path):\n    run_path = Path(remove_prefix(run_path, WANDB_ARTIFACT_PREFIX))\n    run_id = run_path.stem\n    project = run_path.parent.stem\n    model_artifact_name = 'run_' + run_id + '_model'",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "get_run_info",
        "kind": 2,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "def get_run_info(run_path):\n    run_path = Path(remove_prefix(run_path, WANDB_ARTIFACT_PREFIX))\n    run_id = run_path.stem\n    project = run_path.parent.stem\n    model_artifact_name = 'run_' + run_id + '_model'\n    return run_id, project, model_artifact_name\ndef check_wandb_resume(opt):\n    process_wandb_config_ddp_mode(opt) if opt.global_rank not in [-1, 0] else None\n    if isinstance(opt.resume, str):\n        if opt.resume.startswith(WANDB_ARTIFACT_PREFIX):",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "check_wandb_resume",
        "kind": 2,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "def check_wandb_resume(opt):\n    process_wandb_config_ddp_mode(opt) if opt.global_rank not in [-1, 0] else None\n    if isinstance(opt.resume, str):\n        if opt.resume.startswith(WANDB_ARTIFACT_PREFIX):\n            if opt.global_rank not in [-1, 0]:  # For resuming DDP runs\n                run_id, project, model_artifact_name = get_run_info(opt.resume)\n                api = wandb.Api()\n                artifact = api.artifact(project + '/' + model_artifact_name + ':latest')\n                modeldir = artifact.download()\n                opt.weights = str(Path(modeldir) / \"last.pt\")",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "process_wandb_config_ddp_mode",
        "kind": 2,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "def process_wandb_config_ddp_mode(opt):\n    with open(opt.data) as f:\n        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n    train_dir, val_dir = None, None\n    if isinstance(data_dict['train'], str) and data_dict['train'].startswith(WANDB_ARTIFACT_PREFIX):\n        api = wandb.Api()\n        train_artifact = api.artifact(remove_prefix(data_dict['train']) + ':' + opt.artifact_alias)\n        train_dir = train_artifact.download()\n        train_path = Path(train_dir) / 'data/images/'\n        data_dict['train'] = str(train_path)",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "WANDB_ARTIFACT_PREFIX",
        "kind": 5,
        "importPath": "yolov7.utils.wandb_logging.wandb_utils",
        "description": "yolov7.utils.wandb_logging.wandb_utils",
        "peekOfCode": "WANDB_ARTIFACT_PREFIX = 'wandb-artifact://'\ndef remove_prefix(from_string, prefix=WANDB_ARTIFACT_PREFIX):\n    return from_string[len(prefix):]\ndef check_wandb_config_file(data_config_file):\n    wandb_config = '_wandb.'.join(data_config_file.rsplit('.', 1))  # updated data.yaml path\n    if Path(wandb_config).is_file():\n        return wandb_config\n    return data_config_file\ndef get_run_info(run_path):\n    run_path = Path(remove_prefix(run_path, WANDB_ARTIFACT_PREFIX))",
        "detail": "yolov7.utils.wandb_logging.wandb_utils",
        "documentation": {}
    },
    {
        "label": "SiLU",
        "kind": 6,
        "importPath": "yolov7.utils.activations",
        "description": "yolov7.utils.activations",
        "peekOfCode": "class SiLU(nn.Module):  # export-friendly version of nn.SiLU()\n    @staticmethod\n    def forward(x):\n        return x * torch.sigmoid(x)\nclass Hardswish(nn.Module):  # export-friendly version of nn.Hardswish()\n    @staticmethod\n    def forward(x):\n        # return x * F.hardsigmoid(x)  # for torchscript and CoreML\n        return x * F.hardtanh(x + 3, 0., 6.) / 6.  # for torchscript, CoreML and ONNX\nclass MemoryEfficientSwish(nn.Module):",
        "detail": "yolov7.utils.activations",
        "documentation": {}
    },
    {
        "label": "Hardswish",
        "kind": 6,
        "importPath": "yolov7.utils.activations",
        "description": "yolov7.utils.activations",
        "peekOfCode": "class Hardswish(nn.Module):  # export-friendly version of nn.Hardswish()\n    @staticmethod\n    def forward(x):\n        # return x * F.hardsigmoid(x)  # for torchscript and CoreML\n        return x * F.hardtanh(x + 3, 0., 6.) / 6.  # for torchscript, CoreML and ONNX\nclass MemoryEfficientSwish(nn.Module):\n    class F(torch.autograd.Function):\n        @staticmethod\n        def forward(ctx, x):\n            ctx.save_for_backward(x)",
        "detail": "yolov7.utils.activations",
        "documentation": {}
    },
    {
        "label": "MemoryEfficientSwish",
        "kind": 6,
        "importPath": "yolov7.utils.activations",
        "description": "yolov7.utils.activations",
        "peekOfCode": "class MemoryEfficientSwish(nn.Module):\n    class F(torch.autograd.Function):\n        @staticmethod\n        def forward(ctx, x):\n            ctx.save_for_backward(x)\n            return x * torch.sigmoid(x)\n        @staticmethod\n        def backward(ctx, grad_output):\n            x = ctx.saved_tensors[0]\n            sx = torch.sigmoid(x)",
        "detail": "yolov7.utils.activations",
        "documentation": {}
    },
    {
        "label": "Mish",
        "kind": 6,
        "importPath": "yolov7.utils.activations",
        "description": "yolov7.utils.activations",
        "peekOfCode": "class Mish(nn.Module):\n    @staticmethod\n    def forward(x):\n        return x * F.softplus(x).tanh()\nclass MemoryEfficientMish(nn.Module):\n    class F(torch.autograd.Function):\n        @staticmethod\n        def forward(ctx, x):\n            ctx.save_for_backward(x)\n            return x.mul(torch.tanh(F.softplus(x)))  # x * tanh(ln(1 + exp(x)))",
        "detail": "yolov7.utils.activations",
        "documentation": {}
    },
    {
        "label": "MemoryEfficientMish",
        "kind": 6,
        "importPath": "yolov7.utils.activations",
        "description": "yolov7.utils.activations",
        "peekOfCode": "class MemoryEfficientMish(nn.Module):\n    class F(torch.autograd.Function):\n        @staticmethod\n        def forward(ctx, x):\n            ctx.save_for_backward(x)\n            return x.mul(torch.tanh(F.softplus(x)))  # x * tanh(ln(1 + exp(x)))\n        @staticmethod\n        def backward(ctx, grad_output):\n            x = ctx.saved_tensors[0]\n            sx = torch.sigmoid(x)",
        "detail": "yolov7.utils.activations",
        "documentation": {}
    },
    {
        "label": "FReLU",
        "kind": 6,
        "importPath": "yolov7.utils.activations",
        "description": "yolov7.utils.activations",
        "peekOfCode": "class FReLU(nn.Module):\n    def __init__(self, c1, k=3):  # ch_in, kernel\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c1, k, 1, 1, groups=c1, bias=False)\n        self.bn = nn.BatchNorm2d(c1)\n    def forward(self, x):\n        return torch.max(x, self.bn(self.conv(x)))",
        "detail": "yolov7.utils.activations",
        "documentation": {}
    },
    {
        "label": "RegisterNMS",
        "kind": 6,
        "importPath": "yolov7.utils.add_nms",
        "description": "yolov7.utils.add_nms",
        "peekOfCode": "class RegisterNMS(object):\n    def __init__(\n        self,\n        onnx_model_path: str,\n        precision: str = \"fp32\",\n    ):\n        self.graph = gs.import_onnx(onnx.load(onnx_model_path))\n        assert self.graph\n        LOGGER.info(\"ONNX graph created successfully\")\n        # Fold constants via ONNX-GS that PyTorch2ONNX may have missed",
        "detail": "yolov7.utils.add_nms",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "kind": 5,
        "importPath": "yolov7.utils.add_nms",
        "description": "yolov7.utils.add_nms",
        "peekOfCode": "LOGGER = logging.getLogger(__name__)\nclass RegisterNMS(object):\n    def __init__(\n        self,\n        onnx_model_path: str,\n        precision: str = \"fp32\",\n    ):\n        self.graph = gs.import_onnx(onnx.load(onnx_model_path))\n        assert self.graph\n        LOGGER.info(\"ONNX graph created successfully\")",
        "detail": "yolov7.utils.add_nms",
        "documentation": {}
    },
    {
        "label": "check_anchor_order",
        "kind": 2,
        "importPath": "yolov7.utils.autoanchor",
        "description": "yolov7.utils.autoanchor",
        "peekOfCode": "def check_anchor_order(m):\n    # Check anchor order against stride order for YOLO Detect() module m, and correct if necessary\n    a = m.anchor_grid.prod(-1).view(-1)  # anchor area\n    da = a[-1] - a[0]  # delta a\n    ds = m.stride[-1] - m.stride[0]  # delta s\n    if da.sign() != ds.sign():  # same order\n        print('Reversing anchor order')\n        m.anchors[:] = m.anchors.flip(0)\n        m.anchor_grid[:] = m.anchor_grid.flip(0)\ndef check_anchors(dataset, model, thr=4.0, imgsz=640):",
        "detail": "yolov7.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_anchors",
        "kind": 2,
        "importPath": "yolov7.utils.autoanchor",
        "description": "yolov7.utils.autoanchor",
        "peekOfCode": "def check_anchors(dataset, model, thr=4.0, imgsz=640):\n    # Check anchor fit to data, recompute if necessary\n    prefix = colorstr('autoanchor: ')\n    print(f'\\n{prefix}Analyzing anchors... ', end='')\n    m = model.module.model[-1] if hasattr(model, 'module') else model.model[-1]  # Detect()\n    shapes = imgsz * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    scale = np.random.uniform(0.9, 1.1, size=(shapes.shape[0], 1))  # augment scale\n    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(shapes * scale, dataset.labels)])).float()  # wh\n    def metric(k):  # compute metric\n        r = wh[:, None] / k[None]",
        "detail": "yolov7.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "kmean_anchors",
        "kind": 2,
        "importPath": "yolov7.utils.autoanchor",
        "description": "yolov7.utils.autoanchor",
        "peekOfCode": "def kmean_anchors(path='./data/coco.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):\n    \"\"\" Creates kmeans-evolved anchors from training dataset\n        Arguments:\n            path: path to dataset *.yaml, or a loaded dataset\n            n: number of anchors\n            img_size: image size used for training\n            thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0\n            gen: generations to evolve anchors using genetic algorithm\n            verbose: print all results\n        Return:",
        "detail": "yolov7.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "InfiniteDataLoader",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class InfiniteDataLoader(torch.utils.data.dataloader.DataLoader):\n    \"\"\" Dataloader that reuses workers\n    Uses same syntax as vanilla DataLoader\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))\n        self.iterator = super().__iter__()\n    def __len__(self):\n        return len(self.batch_sampler.sampler)",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "_RepeatSampler",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class _RepeatSampler(object):\n    \"\"\" Sampler that repeats forever\n    Args:\n        sampler (Sampler)\n    \"\"\"\n    def __init__(self, sampler):\n        self.sampler = sampler\n    def __iter__(self):\n        while True:\n            yield from iter(self.sampler)",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class LoadImages:  # for inference\n    def __init__(self, path, img_size=640, stride=32):\n        p = str(Path(path).absolute())  # os-agnostic absolute path\n        if '*' in p:\n            files = sorted(glob.glob(p, recursive=True))  # glob\n        elif os.path.isdir(p):\n            files = sorted(glob.glob(os.path.join(p, '*.*')))  # dir\n        elif os.path.isfile(p):\n            files = [p]  # files\n        else:",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadWebcam",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class LoadWebcam:  # for inference\n    def __init__(self, pipe='0', img_size=640, stride=32):\n        self.img_size = img_size\n        self.stride = stride\n        if pipe.isnumeric():\n            pipe = eval(pipe)  # local camera\n        # pipe = 'rtsp://192.168.1.64/1'  # IP camera\n        # pipe = 'rtsp://username:password@192.168.1.64/1'  # IP camera with login\n        # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg'  # IP golf camera\n        self.pipe = pipe",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class LoadStreams:  # multiple IP or RTSP cameras\n    def __init__(self, sources='streams.txt', img_size=640, stride=32):\n        self.mode = 'stream'\n        self.img_size = img_size\n        self.stride = stride\n        if os.path.isfile(sources):\n            with open(sources, 'r') as f:\n                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip())]\n        else:\n            sources = [sources]",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndLabels",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class LoadImagesAndLabels(Dataset):  # for training/testing\n    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,\n                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):\n        self.img_size = img_size\n        self.augment = augment\n        self.hyp = hyp\n        self.image_weights = image_weights\n        self.rect = False if image_weights else rect\n        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)\n        self.mosaic_border = [-img_size // 2, -img_size // 2]",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "Albumentations",
        "kind": 6,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "class Albumentations:\n    # YOLOv5 Albumentations class (optional, only used if package is installed)\n    def __init__(self):\n        self.transform = None\n        import albumentations as A\n        self.transform = A.Compose([\n            A.CLAHE(p=0.01),\n            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.01),\n            A.RandomGamma(gamma_limit=[80, 120], p=0.01),\n            A.Blur(p=0.01),",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def get_hash(files):\n    # Returns a single hash value of a list of files\n    return sum(os.path.getsize(f) for f in files if os.path.isfile(f))\ndef exif_size(img):\n    # Returns exif-corrected PIL size\n    s = img.size  # (width, height)\n    try:\n        rotation = dict(img._getexif().items())[orientation]\n        if rotation == 6:  # rotation 270\n            s = (s[1], s[0])",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "exif_size",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def exif_size(img):\n    # Returns exif-corrected PIL size\n    s = img.size  # (width, height)\n    try:\n        rotation = dict(img._getexif().items())[orientation]\n        if rotation == 6:  # rotation 270\n            s = (s[1], s[0])\n        elif rotation == 8:  # rotation 90\n            s = (s[1], s[0])\n    except:",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def create_dataloader(path, imgsz, batch_size, stride, opt, hyp=None, augment=False, cache=False, pad=0.0, rect=False,\n                      rank=-1, world_size=1, workers=8, image_weights=False, quad=False, prefix=''):\n    # Make sure only the first process in DDP process the dataset first, and the following others can use the cache\n    with torch_distributed_zero_first(rank):\n        dataset = LoadImagesAndLabels(path, imgsz, batch_size,\n                                      augment=augment,  # augment images\n                                      hyp=hyp,  # augmentation hyperparameters\n                                      rect=rect,  # rectangular training\n                                      cache_images=cache,\n                                      single_cls=opt.single_cls,",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def img2label_paths(img_paths):\n    # Define label paths as a function of image paths\n    sa, sb = os.sep + 'images' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings\n    return ['txt'.join(x.replace(sa, sb, 1).rsplit(x.split('.')[-1], 1)) for x in img_paths]\nclass LoadImagesAndLabels(Dataset):  # for training/testing\n    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,\n                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):\n        self.img_size = img_size\n        self.augment = augment\n        self.hyp = hyp",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "load_image",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def load_image(self, index):\n    # loads 1 image from dataset, returns img, original hw, resized hw\n    img = self.imgs[index]\n    if img is None:  # not cached\n        path = self.img_files[index]\n        img = cv2.imread(path)  # BGR\n        assert img is not None, 'Image Not Found ' + path\n        h0, w0 = img.shape[:2]  # orig hw\n        r = self.img_size / max(h0, w0)  # resize image to img_size\n        if r != 1:  # always resize down, only resize up if training with augmentation",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "augment_hsv",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):\n    r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\n    hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n    dtype = img.dtype  # uint8\n    x = np.arange(0, 256, dtype=np.int16)\n    lut_hue = ((x * r[0]) % 180).astype(dtype)\n    lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n    lut_val = np.clip(x * r[2], 0, 255).astype(dtype)\n    img_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val))).astype(dtype)\n    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "hist_equalize",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def hist_equalize(img, clahe=True, bgr=False):\n    # Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255\n    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV if bgr else cv2.COLOR_RGB2YUV)\n    if clahe:\n        c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        yuv[:, :, 0] = c.apply(yuv[:, :, 0])\n    else:\n        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])  # equalize Y channel histogram\n    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR if bgr else cv2.COLOR_YUV2RGB)  # convert YUV image to RGB\ndef load_mosaic(self, index):",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "load_mosaic",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def load_mosaic(self, index):\n    # loads images in a 4-mosaic\n    labels4, segments4 = [], []\n    s = self.img_size\n    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]  # mosaic center x, y\n    indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices\n    for i, index in enumerate(indices):\n        # Load image\n        img, _, (h, w) = load_image(self, index)\n        # place img in img4",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "load_mosaic9",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def load_mosaic9(self, index):\n    # loads images in a 9-mosaic\n    labels9, segments9 = [], []\n    s = self.img_size\n    indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices\n    for i, index in enumerate(indices):\n        # Load image\n        img, _, (h, w) = load_image(self, index)\n        # place img in img9\n        if i == 0:  # center",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "load_samples",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def load_samples(self, index):\n    # loads images in a 4-mosaic\n    labels4, segments4 = [], []\n    s = self.img_size\n    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]  # mosaic center x, y\n    indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices\n    for i, index in enumerate(indices):\n        # Load image\n        img, _, (h, w) = load_image(self, index)\n        # place img in img4",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "copy_paste",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def copy_paste(img, labels, segments, probability=0.5):\n    # Implement Copy-Paste augmentation https://arxiv.org/abs/2012.07177, labels as nx5 np.array(cls, xyxy)\n    n = len(segments)\n    if probability and n:\n        h, w, c = img.shape  # height, width, channels\n        im_new = np.zeros(img.shape, np.uint8)\n        for j in random.sample(range(n), k=round(probability * n)):\n            l, s = labels[j], segments[j]\n            box = w - l[3], l[2], w - l[1], l[4]\n            ioa = bbox_ioa(box, labels[:, 1:5])  # intersection over area",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "remove_background",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def remove_background(img, labels, segments):\n    # Implement Copy-Paste augmentation https://arxiv.org/abs/2012.07177, labels as nx5 np.array(cls, xyxy)\n    n = len(segments)\n    h, w, c = img.shape  # height, width, channels\n    im_new = np.zeros(img.shape, np.uint8)\n    img_new = np.ones(img.shape, np.uint8) * 114\n    for j in range(n):\n        cv2.drawContours(im_new, [segments[j].astype(np.int32)], -1, (255, 255, 255), cv2.FILLED)\n        result = cv2.bitwise_and(src1=img, src2=im_new)\n        i = result > 0  # pixels to replace",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "sample_segments",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def sample_segments(img, labels, segments, probability=0.5):\n    # Implement Copy-Paste augmentation https://arxiv.org/abs/2012.07177, labels as nx5 np.array(cls, xyxy)\n    n = len(segments)\n    sample_labels = []\n    sample_images = []\n    sample_masks = []\n    if probability and n:\n        h, w, c = img.shape  # height, width, channels\n        for j in random.sample(range(n), k=round(probability * n)):\n            l, s = labels[j], segments[j]",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "replicate",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def replicate(img, labels):\n    # Replicate labels\n    h, w = img.shape[:2]\n    boxes = labels[:, 1:].astype(int)\n    x1, y1, x2, y2 = boxes.T\n    s = ((x2 - x1) + (y2 - y1)) / 2  # side length (pixels)\n    for i in s.argsort()[:round(s.size * 0.5)]:  # smallest indices\n        x1b, y1b, x2b, y2b = boxes[i]\n        bh, bw = y2b - y1b, x2b - x1b\n        yc, xc = int(random.uniform(0, h - bh)), int(random.uniform(0, w - bw))  # offset x, y",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "letterbox",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n    # Resize and pad image while meeting stride-multiple constraints\n    shape = img.shape[:2]  # current shape [height, width]\n    if isinstance(new_shape, int):\n        new_shape = (new_shape, new_shape)\n    # Scale ratio (new / old)\n    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n        r = min(r, 1.0)\n    # Compute padding",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "random_perspective",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def random_perspective(img, targets=(), segments=(), degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0,\n                       border=(0, 0)):\n    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\n    # targets = [cls, xyxy]\n    height = img.shape[0] + border[0] * 2  # shape(h,w,c)\n    width = img.shape[1] + border[1] * 2\n    # Center\n    C = np.eye(3)\n    C[0, 2] = -img.shape[1] / 2  # x translation (pixels)\n    C[1, 2] = -img.shape[0] / 2  # y translation (pixels)",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "box_candidates",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def box_candidates(box1, box2, wh_thr=2, ar_thr=20, area_thr=0.1, eps=1e-16):  # box1(4,n), box2(4,n)\n    # Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio\n    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]\n    ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # aspect ratio\n    return (w2 > wh_thr) & (h2 > wh_thr) & (w2 * h2 / (w1 * h1 + eps) > area_thr) & (ar < ar_thr)  # candidates\ndef bbox_ioa(box1, box2):\n    # Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2\n    box2 = box2.transpose()\n    # Get the coordinates of bounding boxes",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def bbox_ioa(box1, box2):\n    # Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2\n    box2 = box2.transpose()\n    # Get the coordinates of bounding boxes\n    b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n    b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n    # Intersection area\n    inter_area = (np.minimum(b1_x2, b2_x2) - np.maximum(b1_x1, b2_x1)).clip(0) * \\\n                 (np.minimum(b1_y2, b2_y2) - np.maximum(b1_y1, b2_y1)).clip(0)\n    # box2 area",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "cutout",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def cutout(image, labels):\n    # Applies image cutout augmentation https://arxiv.org/abs/1708.04552\n    h, w = image.shape[:2]\n    # create random masks\n    scales = [0.5] * 1 + [0.25] * 2 + [0.125] * 4 + [0.0625] * 8 + [0.03125] * 16  # image size fraction\n    for s in scales:\n        mask_h = random.randint(1, int(h * s))\n        mask_w = random.randint(1, int(w * s))\n        # box\n        xmin = max(0, random.randint(0, w) - mask_w // 2)",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "pastein",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def pastein(image, labels, sample_labels, sample_images, sample_masks):\n    # Applies image cutout augmentation https://arxiv.org/abs/1708.04552\n    h, w = image.shape[:2]\n    # create random masks\n    scales = [0.75] * 2 + [0.5] * 4 + [0.25] * 4 + [0.125] * 4 + [0.0625] * 6  # image size fraction\n    for s in scales:\n        if random.random() < 0.2:\n            continue\n        mask_h = random.randint(1, int(h * s))\n        mask_w = random.randint(1, int(w * s))",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "create_folder",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def create_folder(path='./new'):\n    # Create folder\n    if os.path.exists(path):\n        shutil.rmtree(path)  # delete output folder\n    os.makedirs(path)  # make new output folder\ndef flatten_recursive(path='../coco'):\n    # Flatten a recursive directory by bringing all files to top level\n    new_path = Path(path + '_flat')\n    create_folder(new_path)\n    for file in tqdm(glob.glob(str(Path(path)) + '/**/*.*', recursive=True)):",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "flatten_recursive",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def flatten_recursive(path='../coco'):\n    # Flatten a recursive directory by bringing all files to top level\n    new_path = Path(path + '_flat')\n    create_folder(new_path)\n    for file in tqdm(glob.glob(str(Path(path)) + '/**/*.*', recursive=True)):\n        shutil.copyfile(file, new_path / Path(file).name)\ndef extract_boxes(path='../coco/'):  # from utils.datasets import *; extract_boxes('../coco128')\n    # Convert detection dataset into classification dataset, with one directory per class\n    path = Path(path)  # images dir\n    shutil.rmtree(path / 'classifier') if (path / 'classifier').is_dir() else None  # remove existing",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "extract_boxes",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def extract_boxes(path='../coco/'):  # from utils.datasets import *; extract_boxes('../coco128')\n    # Convert detection dataset into classification dataset, with one directory per class\n    path = Path(path)  # images dir\n    shutil.rmtree(path / 'classifier') if (path / 'classifier').is_dir() else None  # remove existing\n    files = list(path.rglob('*.*'))\n    n = len(files)  # number of files\n    for im_file in tqdm(files, total=n):\n        if im_file.suffix[1:] in img_formats:\n            # image\n            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "autosplit",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def autosplit(path='../coco', weights=(0.9, 0.1, 0.0), annotated_only=False):\n    \"\"\" Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files\n    Usage: from utils.datasets import *; autosplit('../coco')\n    Arguments\n        path:           Path to images directory\n        weights:        Train, val, test weights (list)\n        annotated_only: Only use images with an annotated txt file\n    \"\"\"\n    path = Path(path)  # images dir\n    files = sum([list(path.rglob(f\"*.{img_ext}\")) for img_ext in img_formats], [])  # image files only",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "load_segmentations",
        "kind": 2,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "def load_segmentations(self, index):\n    key = '/work/handsomejw66/coco17/' + self.img_files[index]\n    #print(key)\n    # /work/handsomejw66/coco17/\n    return self.segs[key]",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "help_url",
        "kind": 5,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "help_url = 'https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'\nimg_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes\nvid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes\nlogger = logging.getLogger(__name__)\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(files):\n    # Returns a single hash value of a list of files",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "img_formats",
        "kind": 5,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes\nvid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes\nlogger = logging.getLogger(__name__)\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(files):\n    # Returns a single hash value of a list of files\n    return sum(os.path.getsize(f) for f in files if os.path.isfile(f))",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "vid_formats",
        "kind": 5,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes\nlogger = logging.getLogger(__name__)\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(files):\n    # Returns a single hash value of a list of files\n    return sum(os.path.getsize(f) for f in files if os.path.isfile(f))\ndef exif_size(img):",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov7.utils.datasets",
        "description": "yolov7.utils.datasets",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(files):\n    # Returns a single hash value of a list of files\n    return sum(os.path.getsize(f) for f in files if os.path.isfile(f))\ndef exif_size(img):\n    # Returns exif-corrected PIL size",
        "detail": "yolov7.utils.datasets",
        "documentation": {}
    },
    {
        "label": "set_logging",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def set_logging(rank=-1):\n    logging.basicConfig(\n        format=\"%(message)s\",\n        level=logging.INFO if rank in [-1, 0] else logging.WARN)\ndef init_seeds(seed=0):\n    # Initialize random number generator (RNG) seeds\n    random.seed(seed)\n    np.random.seed(seed)\n    init_torch_seeds(seed)\ndef get_latest_run(search_dir='.'):",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def init_seeds(seed=0):\n    # Initialize random number generator (RNG) seeds\n    random.seed(seed)\n    np.random.seed(seed)\n    init_torch_seeds(seed)\ndef get_latest_run(search_dir='.'):\n    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)\n    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else ''\ndef isdocker():",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def get_latest_run(search_dir='.'):\n    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)\n    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else ''\ndef isdocker():\n    # Is environment a Docker container\n    return Path('/workspace').exists()  # or Path('/.dockerenv').exists()\ndef emojis(str=''):\n    # Return platform-dependent emoji-safe version of string\n    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "isdocker",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def isdocker():\n    # Is environment a Docker container\n    return Path('/workspace').exists()  # or Path('/.dockerenv').exists()\ndef emojis(str=''):\n    # Return platform-dependent emoji-safe version of string\n    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str\ndef check_online():\n    # Check internet connectivity\n    import socket\n    try:",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "emojis",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def emojis(str=''):\n    # Return platform-dependent emoji-safe version of string\n    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str\ndef check_online():\n    # Check internet connectivity\n    import socket\n    try:\n        socket.create_connection((\"1.1.1.1\", 443), 5)  # check host accesability\n        return True\n    except OSError:",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_online",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_online():\n    # Check internet connectivity\n    import socket\n    try:\n        socket.create_connection((\"1.1.1.1\", 443), 5)  # check host accesability\n        return True\n    except OSError:\n        return False\ndef check_git_status():\n    # Recommend 'git pull' if code is out of date",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_status",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_git_status():\n    # Recommend 'git pull' if code is out of date\n    print(colorstr('github: '), end='')\n    try:\n        assert Path('.git').exists(), 'skipping check (not a git repository)'\n        assert not isdocker(), 'skipping check (Docker image)'\n        assert check_online(), 'skipping check (offline)'\n        cmd = 'git fetch && git config --get remote.origin.url'\n        url = subprocess.check_output(cmd, shell=True).decode().strip().rstrip('.git')  # github repo url\n        branch = subprocess.check_output('git rev-parse --abbrev-ref HEAD', shell=True).decode().strip()  # checked out",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_requirements(requirements='requirements.txt', exclude=()):\n    # Check installed dependencies meet requirements (pass *.txt file or list of packages)\n    import pkg_resources as pkg\n    prefix = colorstr('red', 'bold', 'requirements:')\n    if isinstance(requirements, (str, Path)):  # requirements.txt file\n        file = Path(requirements)\n        if not file.exists():\n            print(f\"{prefix} {file.resolve()} not found, check failed.\")\n            return\n        requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(file.open()) if x.name not in exclude]",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_img_size(img_size, s=32):\n    # Verify img_size is a multiple of stride s\n    new_size = make_divisible(img_size, int(s))  # ceil gs-multiple\n    if new_size != img_size:\n        print('WARNING: --img-size %g must be multiple of max stride %g, updating to %g' % (img_size, s, new_size))\n    return new_size\ndef check_imshow():\n    # Check if environment supports image displays\n    try:\n        assert not isdocker(), 'cv2.imshow() is disabled in Docker environments'",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_imshow():\n    # Check if environment supports image displays\n    try:\n        assert not isdocker(), 'cv2.imshow() is disabled in Docker environments'\n        cv2.imshow('test', np.zeros((1, 1, 3)))\n        cv2.waitKey(1)\n        cv2.destroyAllWindows()\n        cv2.waitKey(1)\n        return True\n    except Exception as e:",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_file(file):\n    # Search for file if not found\n    if Path(file).is_file() or file == '':\n        return file\n    else:\n        files = glob.glob('./**/' + file, recursive=True)  # find file\n        assert len(files), f'File Not Found: {file}'  # assert file was found\n        assert len(files) == 1, f\"Multiple files match '{file}', specify exact path: {files}\"  # assert unique\n        return files[0]  # return file\ndef check_dataset(dict):",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def check_dataset(dict):\n    # Download dataset if not found locally\n    val, s = dict.get('val'), dict.get('download')\n    if val and len(val):\n        val = [Path(x).resolve() for x in (val if isinstance(val, list) else [val])]  # val path\n        if not all(x.exists() for x in val):\n            print('\\nWARNING: Dataset not found, nonexistent paths: %s' % [str(x) for x in val if not x.exists()])\n            if s and len(s):  # download script\n                print('Downloading %s ...' % s)\n                if s.startswith('http') and s.endswith('.zip'):  # URL",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def make_divisible(x, divisor):\n    # Returns x evenly divisible by divisor\n    return math.ceil(x / divisor) * divisor\ndef clean_str(s):\n    # Cleans a string by replacing special characters with underscore _\n    return re.sub(pattern=\"[|@#!$%&()=?^*;:,><+]\", repl=\"_\", string=s)\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    # lambda function for sinusoidal ramp from y1 to y2\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef colorstr(*input):",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "clean_str",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def clean_str(s):\n    # Cleans a string by replacing special characters with underscore _\n    return re.sub(pattern=\"[|@#!$%&()=?^*;:,><+]\", repl=\"_\", string=s)\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    # lambda function for sinusoidal ramp from y1 to y2\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef colorstr(*input):\n    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')\n    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string\n    colors = {'black': '\\033[30m',  # basic colors",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def one_cycle(y1=0.0, y2=1.0, steps=100):\n    # lambda function for sinusoidal ramp from y1 to y2\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef colorstr(*input):\n    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')\n    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string\n    colors = {'black': '\\033[30m',  # basic colors\n              'red': '\\033[31m',\n              'green': '\\033[32m',\n              'yellow': '\\033[33m',",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def colorstr(*input):\n    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')\n    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string\n    colors = {'black': '\\033[30m',  # basic colors\n              'red': '\\033[31m',\n              'green': '\\033[32m',\n              'yellow': '\\033[33m',\n              'blue': '\\033[34m',\n              'magenta': '\\033[35m',\n              'cyan': '\\033[36m',",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_class_weights",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def labels_to_class_weights(labels, nc=80):\n    # Get class weights (inverse frequency) from training labels\n    if labels[0] is None:  # no labels loaded\n        return torch.Tensor()\n    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO\n    classes = labels[:, 0].astype(np.int32)  # labels = [class xywh]\n    weights = np.bincount(classes, minlength=nc)  # occurrences per class\n    # Prepend gridpoint count (for uCE training)\n    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image\n    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_image_weights",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):\n    # Produces image weights based on class_weights and image contents\n    class_counts = np.array([np.bincount(x[:, 0].astype(np.int32), minlength=nc) for x in labels])\n    image_weights = (class_weights.reshape(1, nc) * class_counts).sum(1)\n    # index = random.choices(range(n), weights=image_weights, k=1)  # weight image sample\n    return image_weights\ndef coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)\n    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)\n    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')\n    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco\n    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,\n         35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n         64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n    return x",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def xyxy2xywh(x):\n    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where xy1=top-left, xy2=bottom-right\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # x center\n    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # y center\n    y[:, 2] = x[:, 2] - x[:, 0]  # width\n    y[:, 3] = x[:, 3] - x[:, 1]  # height\n    return y\ndef xywh2xyxy(x):\n    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def xywh2xyxy(x):\n    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n    return y\ndef xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n    # Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n    # Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + padw  # top left x\n    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + padh  # top left y\n    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + padw  # bottom right x\n    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + padh  # bottom right y\n    return y\ndef xyn2xy(x, w=640, h=640, padw=0, padh=0):\n    # Convert normalized segments into pixel segments, shape (n,2)",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "xyn2xy",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def xyn2xy(x, w=640, h=640, padw=0, padh=0):\n    # Convert normalized segments into pixel segments, shape (n,2)\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = w * x[:, 0] + padw  # top left x\n    y[:, 1] = h * x[:, 1] + padh  # top left y\n    return y\ndef segment2box(segment, width=640, height=640):\n    # Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy)\n    x, y = segment.T  # segment xy\n    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def segment2box(segment, width=640, height=640):\n    # Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy)\n    x, y = segment.T  # segment xy\n    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)\n    x, y, = x[inside], y[inside]\n    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # xyxy\ndef segments2boxes(segments):\n    # Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)\n    boxes = []\n    for s in segments:",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def segments2boxes(segments):\n    # Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)\n    boxes = []\n    for s in segments:\n        x, y = s.T  # segment xy\n        boxes.append([x.min(), y.min(), x.max(), y.max()])  # cls, xyxy\n    return xyxy2xywh(np.array(boxes))  # cls, xywh\ndef resample_segments(segments, n=1000):\n    # Up-sample an (n,2) segment\n    for i, s in enumerate(segments):",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def resample_segments(segments, n=1000):\n    # Up-sample an (n,2) segment\n    for i, s in enumerate(segments):\n        s = np.concatenate((s, s[0:1, :]), axis=0)\n        x = np.linspace(0, len(s) - 1, n)\n        xp = np.arange(len(s))\n        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy\n    return segments\ndef scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n    # Rescale coords (xyxy) from img1_shape to img0_shape",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "scale_coords",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n    # Rescale coords (xyxy) from img1_shape to img0_shape\n    if ratio_pad is None:  # calculate from img0_shape\n        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n    else:\n        gain = ratio_pad[0][0]\n        pad = ratio_pad[1]\n    coords[:, [0, 2]] -= pad[0]  # x padding\n    coords[:, [1, 3]] -= pad[1]  # y padding",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "clip_coords",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def clip_coords(boxes, img_shape):\n    # Clip bounding xyxy bounding boxes to image shape (height, width)\n    boxes[:, 0].clamp_(0, img_shape[1])  # x1\n    boxes[:, 1].clamp_(0, img_shape[0])  # y1\n    boxes[:, 2].clamp_(0, img_shape[1])  # x2\n    boxes[:, 3].clamp_(0, img_shape[0])  # y2\ndef bbox_iou(box1, box2, x1y1x2y2=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n    # Returns the IoU of box1 to box2. box1 is 4, box2 is nx4\n    box2 = box2.T\n    # Get the coordinates of bounding boxes",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def bbox_iou(box1, box2, x1y1x2y2=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n    # Returns the IoU of box1 to box2. box1 is 4, box2 is nx4\n    box2 = box2.T\n    # Get the coordinates of bounding boxes\n    if x1y1x2y2:  # x1, y1, x2, y2 = box1\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n    else:  # transform from xywh to xyxy\n        b1_x1, b1_x2 = box1[0] - box1[2] / 2, box1[0] + box1[2] / 2\n        b1_y1, b1_y2 = box1[1] - box1[3] / 2, box1[1] + box1[3] / 2",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "bbox_alpha_iou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def bbox_alpha_iou(box1, box2, x1y1x2y2=False, GIoU=False, DIoU=False, CIoU=False, alpha=2, eps=1e-9):\n    # Returns tsqrt_he IoU of box1 to box2. box1 is 4, box2 is nx4\n    box2 = box2.T\n    # Get the coordinates of bounding boxes\n    if x1y1x2y2:  # x1, y1, x2, y2 = box1\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n    else:  # transform from xywh to xyxy\n        b1_x1, b1_x2 = box1[0] - box1[2] / 2, box1[0] + box1[2] / 2\n        b1_y1, b1_y2 = box1[1] - box1[3] / 2, box1[1] + box1[3] / 2",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def box_iou(box1, box2):\n    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n    \"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        box1 (Tensor[N, 4])\n        box2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "wh_iou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def wh_iou(wh1, wh2):\n    # Returns the nxm IoU matrix. wh1 is nx2, wh2 is mx2\n    wh1 = wh1[:, None]  # [N,1,2]\n    wh2 = wh2[None]  # [1,M,2]\n    inter = torch.min(wh1, wh2).prod(2)  # [N,M]\n    return inter / (wh1.prod(2) + wh2.prod(2) - inter)  # iou = inter / (area1 + area2 - inter)\ndef box_giou(box1, box2):\n    \"\"\"\n    Return generalized intersection-over-union (Jaccard index) between two sets of boxes.\n    Both sets of boxes are expected to be in ``(x1, y1, x2, y2)`` format with",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "box_giou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def box_giou(box1, box2):\n    \"\"\"\n    Return generalized intersection-over-union (Jaccard index) between two sets of boxes.\n    Both sets of boxes are expected to be in ``(x1, y1, x2, y2)`` format with\n    ``0 <= x1 < x2`` and ``0 <= y1 < y2``.\n    Args:\n        boxes1 (Tensor[N, 4]): first set of boxes\n        boxes2 (Tensor[M, 4]): second set of boxes\n    Returns:\n        Tensor[N, M]: the NxM matrix containing the pairwise generalized IoU values",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "box_ciou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def box_ciou(box1, box2, eps: float = 1e-7):\n    \"\"\"\n    Return complete intersection-over-union (Jaccard index) between two sets of boxes.\n    Both sets of boxes are expected to be in ``(x1, y1, x2, y2)`` format with\n    ``0 <= x1 < x2`` and ``0 <= y1 < y2``.\n    Args:\n        boxes1 (Tensor[N, 4]): first set of boxes\n        boxes2 (Tensor[M, 4]): second set of boxes\n        eps (float, optional): small number to prevent division by zero. Default: 1e-7\n    Returns:",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "box_diou",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def box_diou(box1, box2, eps: float = 1e-7):\n    \"\"\"\n    Return distance intersection-over-union (Jaccard index) between two sets of boxes.\n    Both sets of boxes are expected to be in ``(x1, y1, x2, y2)`` format with\n    ``0 <= x1 < x2`` and ``0 <= y1 < y2``.\n    Args:\n        boxes1 (Tensor[N, 4]): first set of boxes\n        boxes2 (Tensor[M, 4]): second set of boxes\n        eps (float, optional): small number to prevent division by zero. Default: 1e-7\n    Returns:",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n                        labels=()):\n    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n    Returns:\n         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n    \"\"\"\n    nc = prediction.shape[2] - 5  # number of classes\n    xc = prediction[..., 4] > conf_thres  # candidates\n    # Settings\n    min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression_kpt",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def non_max_suppression_kpt(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n                        labels=(), kpt_label=False, nc=None, nkpt=None):\n    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n    Returns:\n         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n    \"\"\"\n    if nc is None:\n        nc = prediction.shape[2] - 5  if not kpt_label else prediction.shape[2] - 56 # number of classes\n    xc = prediction[..., 4] > conf_thres  # candidates\n    # Settings",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()\n    # Strip optimizer from 'f' to finalize training, optionally save as 's'\n    x = torch.load(f, map_location=torch.device('cpu'))\n    if x.get('ema'):\n        x['model'] = x['ema']  # replace model with ema\n    for k in 'optimizer', 'training_results', 'wandb_id', 'ema', 'updates':  # keys\n        x[k] = None\n    x['epoch'] = -1\n    x['model'].half()  # to FP16\n    for p in x['model'].parameters():",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "print_mutation",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def print_mutation(hyp, results, yaml_file='hyp_evolved.yaml', bucket=''):\n    # Print mutation results to evolve.txt (for use with train.py --evolve)\n    a = '%10s' * len(hyp) % tuple(hyp.keys())  # hyperparam keys\n    b = '%10.3g' * len(hyp) % tuple(hyp.values())  # hyperparam values\n    c = '%10.4g' * len(results) % results  # results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)\n    print('\\n%s\\n%s\\nEvolved fitness: %s\\n' % (a, b, c))\n    if bucket:\n        url = 'gs://%s/evolve.txt' % bucket\n        if gsutil_getsize(url) > (os.path.getsize('evolve.txt') if os.path.exists('evolve.txt') else 0):\n            os.system('gsutil cp %s .' % url)  # download evolve.txt if larger than local",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "apply_classifier",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def apply_classifier(x, model, img, im0):\n    # applies a second stage classifier to yolo outputs\n    im0 = [im0] if isinstance(im0, np.ndarray) else im0\n    for i, d in enumerate(x):  # per image\n        if d is not None and len(d):\n            d = d.clone()\n            # Reshape and pad cutouts\n            b = xyxy2xywh(d[:, :4])  # boxes\n            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # rectangle to square\n            b[:, 2:] = b[:, 2:] * 1.3 + 30  # pad",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "kind": 2,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "def increment_path(path, exist_ok=True, sep=''):\n    # Increment path, i.e. runs/exp --> runs/exp{sep}0, runs/exp{sep}1 etc.\n    path = Path(path)  # os-agnostic\n    if (path.exists() and exist_ok) or (not path.exists()):\n        return str(path)\n    else:\n        dirs = glob.glob(f\"{path}{sep}*\")  # similar paths\n        matches = [re.search(rf\"%s{sep}(\\d+)\" % path.stem, d) for d in dirs]\n        i = [int(m.groups()[0]) for m in matches if m]  # indices\n        n = max(i) + 1 if i else 2  # increment number",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "pd.options.display.max_columns",
        "kind": 5,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "pd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))  # NumExpr max threads\ndef set_logging(rank=-1):\n    logging.basicConfig(\n        format=\"%(message)s\",\n        level=logging.INFO if rank in [-1, 0] else logging.WARN)\ndef init_seeds(seed=0):\n    # Initialize random number generator (RNG) seeds\n    random.seed(seed)",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "os.environ['NUMEXPR_MAX_THREADS']",
        "kind": 5,
        "importPath": "yolov7.utils.general",
        "description": "yolov7.utils.general",
        "peekOfCode": "os.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))  # NumExpr max threads\ndef set_logging(rank=-1):\n    logging.basicConfig(\n        format=\"%(message)s\",\n        level=logging.INFO if rank in [-1, 0] else logging.WARN)\ndef init_seeds(seed=0):\n    # Initialize random number generator (RNG) seeds\n    random.seed(seed)\n    np.random.seed(seed)\n    init_torch_seeds(seed)",
        "detail": "yolov7.utils.general",
        "documentation": {}
    },
    {
        "label": "gsutil_getsize",
        "kind": 2,
        "importPath": "yolov7.utils.google_utils",
        "description": "yolov7.utils.google_utils",
        "peekOfCode": "def gsutil_getsize(url=''):\n    # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du\n    s = subprocess.check_output(f'gsutil du {url}', shell=True).decode('utf-8')\n    return eval(s.split(' ')[0]) if len(s) else 0  # bytes\ndef attempt_download(file, repo='WongKinYiu/yolov7'):\n    # Attempt file download if does not exist\n    file = Path(str(file).strip().replace(\"'\", '').lower())\n    if not file.exists():\n        try:\n            response = requests.get(f'https://api.github.com/repos/{repo}/releases/latest').json()  # github api",
        "detail": "yolov7.utils.google_utils",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "kind": 2,
        "importPath": "yolov7.utils.google_utils",
        "description": "yolov7.utils.google_utils",
        "peekOfCode": "def attempt_download(file, repo='WongKinYiu/yolov7'):\n    # Attempt file download if does not exist\n    file = Path(str(file).strip().replace(\"'\", '').lower())\n    if not file.exists():\n        try:\n            response = requests.get(f'https://api.github.com/repos/{repo}/releases/latest').json()  # github api\n            assets = [x['name'] for x in response['assets']]  # release assets\n            tag = response['tag_name']  # i.e. 'v1.0'\n        except:  # fallback plan\n            assets = ['yolov7.pt', 'yolov7-tiny.pt', 'yolov7x.pt', 'yolov7-d6.pt', 'yolov7-e6.pt', ",
        "detail": "yolov7.utils.google_utils",
        "documentation": {}
    },
    {
        "label": "gdrive_download",
        "kind": 2,
        "importPath": "yolov7.utils.google_utils",
        "description": "yolov7.utils.google_utils",
        "peekOfCode": "def gdrive_download(id='', file='tmp.zip'):\n    # Downloads a file from Google Drive. from yolov7.utils.google_utils import *; gdrive_download()\n    t = time.time()\n    file = Path(file)\n    cookie = Path('cookie')  # gdrive cookie\n    print(f'Downloading https://drive.google.com/uc?export=download&id={id} as {file}... ', end='')\n    file.unlink(missing_ok=True)  # remove existing file\n    cookie.unlink(missing_ok=True)  # remove existing cookie\n    # Attempt file download\n    out = \"NUL\" if platform.system() == \"Windows\" else \"/dev/null\"",
        "detail": "yolov7.utils.google_utils",
        "documentation": {}
    },
    {
        "label": "get_token",
        "kind": 2,
        "importPath": "yolov7.utils.google_utils",
        "description": "yolov7.utils.google_utils",
        "peekOfCode": "def get_token(cookie=\"./cookie\"):\n    with open(cookie) as f:\n        for line in f:\n            if \"download\" in line:\n                return line.split()[-1]\n    return \"\"\n# def upload_blob(bucket_name, source_file_name, destination_blob_name):\n#     # Uploads a file to a bucket\n#     # https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\n#",
        "detail": "yolov7.utils.google_utils",
        "documentation": {}
    },
    {
        "label": "BCEBlurWithLogitsLoss",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class BCEBlurWithLogitsLoss(nn.Module):\n    # BCEwithLogitLoss() with reduced missing label effects.\n    def __init__(self, alpha=0.05):\n        super(BCEBlurWithLogitsLoss, self).__init__()\n        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # must be nn.BCEWithLogitsLoss()\n        self.alpha = alpha\n    def forward(self, pred, true):\n        loss = self.loss_fcn(pred, true)\n        pred = torch.sigmoid(pred)  # prob from logits\n        dx = pred - true  # reduce only missing label effects",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "SigmoidBin",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class SigmoidBin(nn.Module):\n    stride = None  # strides computed during build\n    export = False  # onnx export\n    def __init__(self, bin_count=10, min=0.0, max=1.0, reg_scale = 2.0, use_loss_regression=True, use_fw_regression=True, BCE_weight=1.0, smooth_eps=0.0):\n        super(SigmoidBin, self).__init__()\n        self.bin_count = bin_count\n        self.length = bin_count + 1\n        self.min = min\n        self.max = max\n        self.scale = float(max - min)",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "FocalLoss",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class FocalLoss(nn.Module):\n    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        super(FocalLoss, self).__init__()\n        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = loss_fcn.reduction\n        self.loss_fcn.reduction = 'none'  # required to apply FL to each element\n    def forward(self, pred, true):",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "QFocalLoss",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class QFocalLoss(nn.Module):\n    # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        super(QFocalLoss, self).__init__()\n        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = loss_fcn.reduction\n        self.loss_fcn.reduction = 'none'  # required to apply FL to each element\n    def forward(self, pred, true):",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "RankSort",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class RankSort(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, logits, targets, delta_RS=0.50, eps=1e-10): \n        classification_grads=torch.zeros(logits.shape).cuda()\n        #Filter fg logits\n        fg_labels = (targets > 0.)\n        fg_logits = logits[fg_labels]\n        fg_targets = targets[fg_labels]\n        fg_num = len(fg_logits)\n        #Do not use bg with scores less than minimum fg logit",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "aLRPLoss",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class aLRPLoss(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, logits, targets, regression_losses, delta=1., eps=1e-5): \n        classification_grads=torch.zeros(logits.shape).cuda()\n        #Filter fg logits\n        fg_labels = (targets == 1)\n        fg_logits = logits[fg_labels]\n        fg_num = len(fg_logits)\n        #Do not use bg with scores less than minimum fg logit\n        #since changing its score does not have an effect on precision",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "APLoss",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class APLoss(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, logits, targets, delta=1.): \n        classification_grads=torch.zeros(logits.shape).cuda()\n        #Filter fg logits\n        fg_labels = (targets == 1)\n        fg_logits = logits[fg_labels]\n        fg_num = len(fg_logits)\n        #Do not use bg with scores less than minimum fg logit\n        #since changing its score does not have an effect on precision",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class ComputeLoss:\n    # Compute losses\n    def __init__(self, model, autobalance=False):\n        super(ComputeLoss, self).__init__()\n        device = next(model.parameters()).device  # get model device\n        h = model.hyp  # hyperparameters\n        # Define criteria\n        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))\n        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))\n        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLossOTA",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class ComputeLossOTA:\n    # Compute losses\n    def __init__(self, model, autobalance=False):\n        super(ComputeLossOTA, self).__init__()\n        device = next(model.parameters()).device  # get model device\n        h = model.hyp  # hyperparameters\n        # Define criteria\n        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))\n        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))\n        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLossBinOTA",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class ComputeLossBinOTA:\n    # Compute losses\n    def __init__(self, model, autobalance=False):\n        super(ComputeLossBinOTA, self).__init__()\n        device = next(model.parameters()).device  # get model device\n        h = model.hyp  # hyperparameters\n        # Define criteria\n        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))\n        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))\n        #MSEangle = nn.MSELoss().to(device)",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLossAuxOTA",
        "kind": 6,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "class ComputeLossAuxOTA:\n    # Compute losses\n    def __init__(self, model, autobalance=False):\n        super(ComputeLossAuxOTA, self).__init__()\n        device = next(model.parameters()).device  # get model device\n        h = model.hyp  # hyperparameters\n        # Define criteria\n        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))\n        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))\n        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "smooth_BCE",
        "kind": 2,
        "importPath": "yolov7.utils.loss",
        "description": "yolov7.utils.loss",
        "peekOfCode": "def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441\n    # return positive, negative label smoothing BCE targets\n    return 1.0 - 0.5 * eps, 0.5 * eps\nclass BCEBlurWithLogitsLoss(nn.Module):\n    # BCEwithLogitLoss() with reduced missing label effects.\n    def __init__(self, alpha=0.05):\n        super(BCEBlurWithLogitsLoss, self).__init__()\n        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # must be nn.BCEWithLogitsLoss()\n        self.alpha = alpha\n    def forward(self, pred, true):",
        "detail": "yolov7.utils.loss",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "kind": 6,
        "importPath": "yolov7.utils.metrics",
        "description": "yolov7.utils.metrics",
        "peekOfCode": "class ConfusionMatrix:\n    # Updated version of https://github.com/kaanakan/object_detection_confusion_matrix\n    def __init__(self, nc, conf=0.25, iou_thres=0.45):\n        self.matrix = np.zeros((nc + 1, nc + 1))\n        self.nc = nc  # number of classes\n        self.conf = conf\n        self.iou_thres = iou_thres\n    def process_batch(self, detections, labels):\n        \"\"\"\n        Return intersection-over-union (Jaccard index) of boxes.",
        "detail": "yolov7.utils.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "kind": 2,
        "importPath": "yolov7.utils.metrics",
        "description": "yolov7.utils.metrics",
        "peekOfCode": "def fitness(x):\n    # Model fitness as a weighted combination of metrics\n    w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]\n    return (x[:, :4] * w).sum(1)\ndef ap_per_class(tp, conf, pred_cls, target_cls, v5_metric=False, plot=False, save_dir='.', names=()):\n    \"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).",
        "detail": "yolov7.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class",
        "kind": 2,
        "importPath": "yolov7.utils.metrics",
        "description": "yolov7.utils.metrics",
        "peekOfCode": "def ap_per_class(tp, conf, pred_cls, target_cls, v5_metric=False, plot=False, save_dir='.', names=()):\n    \"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).\n        pred_cls:  Predicted object classes (nparray).\n        target_cls:  True object classes (nparray).\n        plot:  Plot precision-recall curve at mAP@0.5\n        save_dir:  Plot save directory",
        "detail": "yolov7.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_ap",
        "kind": 2,
        "importPath": "yolov7.utils.metrics",
        "description": "yolov7.utils.metrics",
        "peekOfCode": "def compute_ap(recall, precision, v5_metric=False):\n    \"\"\" Compute the average precision, given the recall and precision curves\n    # Arguments\n        recall:    The recall curve (list)\n        precision: The precision curve (list)\n        v5_metric: Assume maximum recall to be 1.0, as in YOLOv5, MMDetetion etc.\n    # Returns\n        Average precision, precision curve, recall curve\n    \"\"\"\n    # Append sentinel values to beginning and end",
        "detail": "yolov7.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_pr_curve",
        "kind": 2,
        "importPath": "yolov7.utils.metrics",
        "description": "yolov7.utils.metrics",
        "peekOfCode": "def plot_pr_curve(px, py, ap, save_dir='pr_curve.png', names=()):\n    # Precision-recall curve\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    py = np.stack(py, axis=1)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py.T):\n            ax.plot(px, y, linewidth=1, label=f'{names[i]} {ap[i, 0]:.3f}')  # plot(recall, precision)\n    else:\n        ax.plot(px, py, linewidth=1, color='grey')  # plot(recall, precision)\n    ax.plot(px, py.mean(1), linewidth=3, color='blue', label='all classes %.3f mAP@0.5' % ap[:, 0].mean())",
        "detail": "yolov7.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_mc_curve",
        "kind": 2,
        "importPath": "yolov7.utils.metrics",
        "description": "yolov7.utils.metrics",
        "peekOfCode": "def plot_mc_curve(px, py, save_dir='mc_curve.png', names=(), xlabel='Confidence', ylabel='Metric'):\n    # Metric-confidence curve\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py):\n            ax.plot(px, y, linewidth=1, label=f'{names[i]}')  # plot(confidence, metric)\n    else:\n        ax.plot(px, py.T, linewidth=1, color='grey')  # plot(confidence, metric)\n    y = py.mean(0)\n    ax.plot(px, y, linewidth=3, color='blue', label=f'all classes {y.max():.2f} at {px[y.argmax()]:.3f}')",
        "detail": "yolov7.utils.metrics",
        "documentation": {}
    },
    {
        "label": "color_list",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def color_list():\n    # Return first 10 plt colors as (r,g,b) https://stackoverflow.com/questions/51350872/python-from-color-name-to-rgb\n    def hex2rgb(h):\n        return tuple(int(h[1 + i:1 + i + 2], 16) for i in (0, 2, 4))\n    return [hex2rgb(h) for h in matplotlib.colors.TABLEAU_COLORS.values()]  # or BASE_ (8), CSS4_ (148), XKCD_ (949)\ndef hist2d(x, y, n=100):\n    # 2d histogram used in labels.png and evolve.png\n    xedges, yedges = np.linspace(x.min(), x.max(), n), np.linspace(y.min(), y.max(), n)\n    hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))\n    xidx = np.clip(np.digitize(x, xedges) - 1, 0, hist.shape[0] - 1)",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "hist2d",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def hist2d(x, y, n=100):\n    # 2d histogram used in labels.png and evolve.png\n    xedges, yedges = np.linspace(x.min(), x.max(), n), np.linspace(y.min(), y.max(), n)\n    hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))\n    xidx = np.clip(np.digitize(x, xedges) - 1, 0, hist.shape[0] - 1)\n    yidx = np.clip(np.digitize(y, yedges) - 1, 0, hist.shape[1] - 1)\n    return np.log(hist[xidx, yidx])\ndef butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):\n    # https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy\n    def butter_lowpass(cutoff, fs, order):",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "butter_lowpass_filtfilt",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):\n    # https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy\n    def butter_lowpass(cutoff, fs, order):\n        nyq = 0.5 * fs\n        normal_cutoff = cutoff / nyq\n        return butter(order, normal_cutoff, btype='low', analog=False)\n    b, a = butter_lowpass(cutoff, fs, order=order)\n    return filtfilt(b, a, data)  # forward-backward filter\ndef plot_one_box(x, img, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image img",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_one_box",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image img\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_one_box_PIL",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_one_box_PIL(box, img, color=None, label=None, line_thickness=None):\n    img = Image.fromarray(img)\n    draw = ImageDraw.Draw(img)\n    line_thickness = line_thickness or max(int(min(img.size) / 200), 2)\n    draw.rectangle(box, width=line_thickness, outline=tuple(color))  # plot\n    if label:\n        fontsize = max(round(max(img.size) / 40), 12)\n        font = ImageFont.truetype(\"Arial.ttf\", fontsize)\n        txt_width, txt_height = font.getsize(label)\n        draw.rectangle([box[0], box[1] - txt_height + 4, box[0] + txt_width, box[1]], fill=tuple(color))",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_wh_methods",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_wh_methods():  # from utils.plots import *; plot_wh_methods()\n    # Compares the two methods for width-height anchor multiplication\n    # https://github.com/ultralytics/yolov3/issues/168\n    x = np.arange(-4.0, 4.0, .1)\n    ya = np.exp(x)\n    yb = torch.sigmoid(torch.from_numpy(x)).numpy() * 2\n    fig = plt.figure(figsize=(6, 3), tight_layout=True)\n    plt.plot(x, ya, '.-', label='YOLOv3')\n    plt.plot(x, yb ** 2, '.-', label='YOLOR ^2')\n    plt.plot(x, yb ** 1.6, '.-', label='YOLOR ^1.6')",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def output_to_target(output):\n    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]\n    targets = []\n    for i, o in enumerate(output):\n        for *box, conf, cls in o.cpu().numpy():\n            targets.append([i, cls, *list(*xyxy2xywh(np.array(box)[None])), conf])\n    return np.array(targets)\ndef plot_images(images, targets, paths=None, fname='images.jpg', names=None, max_size=640, max_subplots=16):\n    # Plot image grid with labels\n    if isinstance(images, torch.Tensor):",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_images(images, targets, paths=None, fname='images.jpg', names=None, max_size=640, max_subplots=16):\n    # Plot image grid with labels\n    if isinstance(images, torch.Tensor):\n        images = images.cpu().float().numpy()\n    if isinstance(targets, torch.Tensor):\n        targets = targets.cpu().numpy()\n    # un-normalise\n    if np.max(images[0]) <= 1:\n        images *= 255\n    tl = 3  # line thickness",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_lr_scheduler",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_lr_scheduler(optimizer, scheduler, epochs=300, save_dir=''):\n    # Plot LR simulating training for full epochs\n    optimizer, scheduler = copy(optimizer), copy(scheduler)  # do not modify originals\n    y = []\n    for _ in range(epochs):\n        scheduler.step()\n        y.append(optimizer.param_groups[0]['lr'])\n    plt.plot(y, '.-', label='LR')\n    plt.xlabel('epoch')\n    plt.ylabel('LR')",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_test_txt",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_test_txt():  # from utils.plots import *; plot_test()\n    # Plot test.txt histograms\n    x = np.loadtxt('test.txt', dtype=np.float32)\n    box = xyxy2xywh(x[:, :4])\n    cx, cy = box[:, 0], box[:, 1]\n    fig, ax = plt.subplots(1, 1, figsize=(6, 6), tight_layout=True)\n    ax.hist2d(cx, cy, bins=600, cmax=10, cmin=0)\n    ax.set_aspect('equal')\n    plt.savefig('hist2d.png', dpi=300)\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6), tight_layout=True)",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_targets_txt",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_targets_txt():  # from utils.plots import *; plot_targets_txt()\n    # Plot targets.txt histograms\n    x = np.loadtxt('targets.txt', dtype=np.float32).T\n    s = ['x targets', 'y targets', 'width targets', 'height targets']\n    fig, ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)\n    ax = ax.ravel()\n    for i in range(4):\n        ax[i].hist(x[i], bins=100, label='%.3g +/- %.3g' % (x[i].mean(), x[i].std()))\n        ax[i].legend()\n        ax[i].set_title(s[i])",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_study_txt",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_study_txt(path='', x=None):  # from utils.plots import *; plot_study_txt()\n    # Plot study.txt generated by test.py\n    fig, ax = plt.subplots(2, 4, figsize=(10, 6), tight_layout=True)\n    # ax = ax.ravel()\n    fig2, ax2 = plt.subplots(1, 1, figsize=(8, 4), tight_layout=True)\n    # for f in [Path(path) / f'study_coco_{x}.txt' for x in ['yolor-p6', 'yolor-w6', 'yolor-e6', 'yolor-d6']]:\n    for f in sorted(Path(path).glob('study*.txt')):\n        y = np.loadtxt(f, dtype=np.float32, usecols=[0, 1, 2, 3, 7, 8, 9], ndmin=2).T\n        x = np.arange(y.shape[1]) if x is None else np.array(x)\n        s = ['P', 'R', 'mAP@.5', 'mAP@.5:.95', 't_inference (ms/img)', 't_NMS (ms/img)', 't_total (ms/img)']",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_labels(labels, names=(), save_dir=Path(''), loggers=None):\n    # plot dataset labels\n    print('Plotting labels... ')\n    c, b = labels[:, 0], labels[:, 1:].transpose()  # classes, boxes\n    nc = int(c.max() + 1)  # number of classes\n    colors = color_list()\n    x = pd.DataFrame(b.transpose(), columns=['x', 'y', 'width', 'height'])\n    # seaborn correlogram\n    sns.pairplot(x, corner=True, diag_kind='auto', kind='hist', diag_kws=dict(bins=50), plot_kws=dict(pmax=0.9))\n    plt.savefig(save_dir / 'labels_correlogram.jpg', dpi=200)",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_evolution",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_evolution(yaml_file='data/hyp.finetune.yaml'):  # from utils.plots import *; plot_evolution()\n    # Plot hyperparameter evolution results in evolve.txt\n    with open(yaml_file) as f:\n        hyp = yaml.load(f, Loader=yaml.SafeLoader)\n    x = np.loadtxt('evolve.txt', ndmin=2)\n    f = fitness(x)\n    # weights = (f - f.min()) ** 2  # for weighted results\n    plt.figure(figsize=(10, 12), tight_layout=True)\n    matplotlib.rc('font', **{'size': 8})\n    for i, (k, v) in enumerate(hyp.items()):",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "profile_idetection",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def profile_idetection(start=0, stop=0, labels=(), save_dir=''):\n    # Plot iDetection '*.txt' per-image logs. from utils.plots import *; profile_idetection()\n    ax = plt.subplots(2, 4, figsize=(12, 6), tight_layout=True)[1].ravel()\n    s = ['Images', 'Free Storage (GB)', 'RAM Usage (GB)', 'Battery', 'dt_raw (ms)', 'dt_smooth (ms)', 'real-world FPS']\n    files = list(Path(save_dir).glob('frames*.txt'))\n    for fi, f in enumerate(files):\n        try:\n            results = np.loadtxt(f, ndmin=2).T[:, 90:-30]  # clip first and last rows\n            n = results.shape[1]  # number of rows\n            x = np.arange(start, min(stop, n) if stop else n)",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_results_overlay",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_results_overlay(start=0, stop=0):  # from utils.plots import *; plot_results_overlay()\n    # Plot training 'results*.txt', overlaying train and val losses\n    s = ['train', 'train', 'train', 'Precision', 'mAP@0.5', 'val', 'val', 'val', 'Recall', 'mAP@0.5:0.95']  # legends\n    t = ['Box', 'Objectness', 'Classification', 'P-R', 'mAP-F1']  # titles\n    for f in sorted(glob.glob('results*.txt') + glob.glob('../../Downloads/results*.txt')):\n        results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T\n        n = results.shape[1]  # number of rows\n        x = range(start, min(stop, n) if stop else n)\n        fig, ax = plt.subplots(1, 5, figsize=(14, 3.5), tight_layout=True)\n        ax = ax.ravel()",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_results(start=0, stop=0, bucket='', id=(), labels=(), save_dir=''):\n    # Plot training 'results*.txt'. from utils.plots import *; plot_results(save_dir='runs/train/exp')\n    fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)\n    ax = ax.ravel()\n    s = ['Box', 'Objectness', 'Classification', 'Precision', 'Recall',\n         'val Box', 'val Objectness', 'val Classification', 'mAP@0.5', 'mAP@0.5:0.95']\n    if bucket:\n        # files = ['https://storage.googleapis.com/%s/results%g.txt' % (bucket, x) for x in id]\n        files = ['results%g.txt' % x for x in id]\n        c = ('gsutil cp ' + '%s ' * len(files) + '.') % tuple('gs://%s/results%g.txt' % (bucket, x) for x in id)",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "output_to_keypoint",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def output_to_keypoint(output):\n    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]\n    targets = []\n    for i, o in enumerate(output):\n        kpts = o[:,6:]\n        o = o[:,:6]\n        for index, (*box, conf, cls) in enumerate(o.detach().cpu().numpy()):\n            targets.append([i, cls, *list(*xyxy2xywh(np.array(box)[None])), conf, *list(kpts.detach().cpu().numpy()[index])])\n    return np.array(targets)\ndef plot_skeleton_kpts(im, kpts, steps, orig_shape=None):",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_skeleton_kpts",
        "kind": 2,
        "importPath": "yolov7.utils.plots",
        "description": "yolov7.utils.plots",
        "peekOfCode": "def plot_skeleton_kpts(im, kpts, steps, orig_shape=None):\n    #Plot the skeleton and keypointsfor coco datatset\n    palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],\n                        [230, 230, 0], [255, 153, 255], [153, 204, 255],\n                        [255, 102, 255], [255, 51, 255], [102, 178, 255],\n                        [51, 153, 255], [255, 153, 153], [255, 102, 102],\n                        [255, 51, 51], [153, 255, 153], [102, 255, 102],\n                        [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0],\n                        [255, 255, 255]])\n    skeleton = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],",
        "detail": "yolov7.utils.plots",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "kind": 6,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "class ModelEMA:\n    \"\"\" Model Exponential Moving Average from https://github.com/rwightman/pytorch-image-models\n    Keep a moving average of everything in the model state_dict (parameters and buffers).\n    This is intended to allow functionality like\n    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    A smoothed version of the weights is necessary for some training schemes to perform well.\n    This class is sensitive where it is initialized in the sequence of model init,\n    GPU assignment and distributed training wrappers.\n    \"\"\"\n    def __init__(self, model, decay=0.9999, updates=0):",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "BatchNormXd",
        "kind": 6,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "class BatchNormXd(torch.nn.modules.batchnorm._BatchNorm):\n    def _check_input_dim(self, input):\n        # The only difference between BatchNorm1d, BatchNorm2d, BatchNorm3d, etc\n        # is this method that is overwritten by the sub-class\n        # This original goal of this method was for tensor sanity checks\n        # If you're ok bypassing those sanity checks (eg. if you trust your inference\n        # to provide the right dimensional inputs), then you can just use this method\n        # for easy conversion from SyncBatchNorm\n        # (unfortunately, SyncBatchNorm does not store the original class - if it did\n        #  we could return the one that was originally created)",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TracedModel",
        "kind": 6,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "class TracedModel(nn.Module):\n    def __init__(self, model=None, device=None, img_size=(640,640)): \n        super(TracedModel, self).__init__()\n        print(\" Convert model to Traced-model... \") \n        self.stride = model.stride\n        self.names = model.names\n        self.model = model\n        self.model = revert_sync_batchnorm(self.model)\n        self.model.to('cpu')\n        self.model.eval()",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def torch_distributed_zero_first(local_rank: int):\n    \"\"\"\n    Decorator to make all processes in distributed training wait for each local_master to do something.\n    \"\"\"\n    if local_rank not in [-1, 0]:\n        torch.distributed.barrier()\n    yield\n    if local_rank == 0:\n        torch.distributed.barrier()\ndef init_torch_seeds(seed=0):",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "init_torch_seeds",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def init_torch_seeds(seed=0):\n    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n    torch.manual_seed(seed)\n    if seed == 0:  # slower, more reproducible\n        cudnn.benchmark, cudnn.deterministic = False, True\n    else:  # faster, less reproducible\n        cudnn.benchmark, cudnn.deterministic = True, False\ndef date_modified(path=__file__):\n    # return human-readable file modification date, i.e. '2021-3-26'\n    t = datetime.datetime.fromtimestamp(Path(path).stat().st_mtime)",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "date_modified",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def date_modified(path=__file__):\n    # return human-readable file modification date, i.e. '2021-3-26'\n    t = datetime.datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f'{t.year}-{t.month}-{t.day}'\ndef git_describe(path=Path(__file__).parent):  # path must be a directory\n    # return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe\n    s = f'git -C {path} describe --tags --long --always'\n    try:\n        return subprocess.check_output(s, shell=True, stderr=subprocess.STDOUT).decode()[:-1]\n    except subprocess.CalledProcessError as e:",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "git_describe",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def git_describe(path=Path(__file__).parent):  # path must be a directory\n    # return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe\n    s = f'git -C {path} describe --tags --long --always'\n    try:\n        return subprocess.check_output(s, shell=True, stderr=subprocess.STDOUT).decode()[:-1]\n    except subprocess.CalledProcessError as e:\n        return ''  # not a git repository\ndef select_device(device='', batch_size=None):\n    # device = 'cpu' or '0' or '0,1,2,3'\n    s = f'YOLOR  {git_describe() or date_modified()} torch {torch.__version__} '  # string",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def select_device(device='', batch_size=None):\n    # device = 'cpu' or '0' or '0,1,2,3'\n    s = f'YOLOR  {git_describe() or date_modified()} torch {torch.__version__} '  # string\n    cpu = device.lower() == 'cpu'\n    if cpu:\n        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\n    elif device:  # non-cpu device requested\n        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability\n    cuda = not cpu and torch.cuda.is_available()",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_synchronized",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def time_synchronized():\n    # pytorch-accurate time\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n    return time.time()\ndef profile(x, ops, n=100, device=None):\n    # profile a pytorch module or list of modules. Example usage:\n    #     x = torch.randn(16, 3, 640, 640)  # input\n    #     m1 = lambda x: x * torch.sigmoid(x)\n    #     m2 = nn.SiLU()",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def profile(x, ops, n=100, device=None):\n    # profile a pytorch module or list of modules. Example usage:\n    #     x = torch.randn(16, 3, 640, 640)  # input\n    #     m1 = lambda x: x * torch.sigmoid(x)\n    #     m2 = nn.SiLU()\n    #     profile(x, [m1, m2], n=100)  # profile speed over 100 iterations\n    device = device or torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    x = x.to(device)\n    x.requires_grad = True\n    print(torch.__version__, device.type, torch.cuda.get_device_properties(0) if device.type == 'cuda' else '')",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def is_parallel(model):\n    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\ndef intersect_dicts(da, db, exclude=()):\n    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values\n    return {k: v for k, v in da.items() if k in db and not any(x in k for x in exclude) and v.shape == db[k].shape}\ndef initialize_weights(model):\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:\n            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def intersect_dicts(da, db, exclude=()):\n    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values\n    return {k: v for k, v in da.items() if k in db and not any(x in k for x in exclude) and v.shape == db[k].shape}\ndef initialize_weights(model):\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:\n            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        elif t is nn.BatchNorm2d:\n            m.eps = 1e-3",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def initialize_weights(model):\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:\n            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        elif t is nn.BatchNorm2d:\n            m.eps = 1e-3\n            m.momentum = 0.03\n        elif t in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6]:\n            m.inplace = True",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "find_modules",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def find_modules(model, mclass=nn.Conv2d):\n    # Finds layer indices matching module class 'mclass'\n    return [i for i, m in enumerate(model.module_list) if isinstance(m, mclass)]\ndef sparsity(model):\n    # Return global model sparsity\n    a, b = 0., 0.\n    for p in model.parameters():\n        a += p.numel()\n        b += (p == 0).sum()\n    return b / a",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "sparsity",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def sparsity(model):\n    # Return global model sparsity\n    a, b = 0., 0.\n    for p in model.parameters():\n        a += p.numel()\n        b += (p == 0).sum()\n    return b / a\ndef prune(model, amount=0.3):\n    # Prune model to requested global sparsity\n    import torch.nn.utils.prune as prune",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "prune",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def prune(model, amount=0.3):\n    # Prune model to requested global sparsity\n    import torch.nn.utils.prune as prune\n    print('Pruning model... ', end='')\n    for name, m in model.named_modules():\n        if isinstance(m, nn.Conv2d):\n            prune.l1_unstructured(m, name='weight', amount=amount)  # prune\n            prune.remove(m, 'weight')  # make permanent\n    print(' %.3g global sparsity' % sparsity(model))\ndef fuse_conv_and_bn(conv, bn):",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def fuse_conv_and_bn(conv, bn):\n    # Fuse convolution and batchnorm layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n    fusedconv = nn.Conv2d(conv.in_channels,\n                          conv.out_channels,\n                          kernel_size=conv.kernel_size,\n                          stride=conv.stride,\n                          padding=conv.padding,\n                          groups=conv.groups,\n                          bias=True).requires_grad_(False).to(conv.weight.device)\n    # prepare filters",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def model_info(model, verbose=False, img_size=640):\n    # Model information. img_size may be int or list, i.e. img_size=640 or img_size=[640, 320]\n    n_p = sum(x.numel() for x in model.parameters())  # number parameters\n    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n    if verbose:\n        print('%5s %40s %9s %12s %20s %10s %10s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n        for i, (name, p) in enumerate(model.named_parameters()):\n            name = name.replace('module_list.', '')\n            print('%5g %40s %9s %12g %20s %10.3g %10.3g' %\n                  (i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "load_classifier",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def load_classifier(name='resnet101', n=2):\n    # Loads a pretrained model reshaped to n-class output\n    model = torchvision.models.__dict__[name](pretrained=True)\n    # ResNet model properties\n    # input_size = [3, 224, 224]\n    # input_space = 'RGB'\n    # input_range = [0, 1]\n    # mean = [0.485, 0.456, 0.406]\n    # std = [0.229, 0.224, 0.225]\n    # Reshape output to n classes",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def scale_img(img, ratio=1.0, same_shape=False, gs=32):  # img(16,3,256,416)\n    # scales img(bs,3,y,x) by ratio constrained to gs-multiple\n    if ratio == 1.0:\n        return img\n    else:\n        h, w = img.shape[2:]\n        s = (int(h * ratio), int(w * ratio))  # new size\n        img = F.interpolate(img, size=s, mode='bilinear', align_corners=False)  # resize\n        if not same_shape:  # pad/crop img\n            h, w = [math.ceil(x * ratio / gs) * gs for x in (h, w)]",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "copy_attr",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def copy_attr(a, b, include=(), exclude=()):\n    # Copy attributes from b to a, options to only include [...] and to exclude [...]\n    for k, v in b.__dict__.items():\n        if (len(include) and k not in include) or k.startswith('_') or k in exclude:\n            continue\n        else:\n            setattr(a, k, v)\nclass ModelEMA:\n    \"\"\" Model Exponential Moving Average from https://github.com/rwightman/pytorch-image-models\n    Keep a moving average of everything in the model state_dict (parameters and buffers).",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "revert_sync_batchnorm",
        "kind": 2,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "def revert_sync_batchnorm(module):\n    # this is very similar to the function that it is trying to revert:\n    # https://github.com/pytorch/pytorch/blob/c8b3686a3e4ba63dc59e5dcfe5db3430df256833/torch/nn/modules/batchnorm.py#L679\n    module_output = module\n    if isinstance(module, torch.nn.modules.batchnorm.SyncBatchNorm):\n        new_cls = BatchNormXd\n        module_output = BatchNormXd(module.num_features,\n                                               module.eps, module.momentum,\n                                               module.affine,\n                                               module.track_running_stats)",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov7.utils.torch_utils",
        "description": "yolov7.utils.torch_utils",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"\n    Decorator to make all processes in distributed training wait for each local_master to do something.\n    \"\"\"\n    if local_rank not in [-1, 0]:\n        torch.distributed.barrier()\n    yield\n    if local_rank == 0:",
        "detail": "yolov7.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 2,
        "importPath": "yolov7.detect",
        "description": "yolov7.detect",
        "peekOfCode": "def detect(save_img=False):\n    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n    # Directories\n    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n    # Initialize\n    set_logging()",
        "detail": "yolov7.detect",
        "documentation": {}
    },
    {
        "label": "create",
        "kind": 2,
        "importPath": "yolov7.hubconf",
        "description": "yolov7.hubconf",
        "peekOfCode": "def create(name, pretrained, channels, classes, autoshape):\n    \"\"\"Creates a specified model\n    Arguments:\n        name (str): name of model, i.e. 'yolov7'\n        pretrained (bool): load pretrained weights into the model\n        channels (int): number of input channels\n        classes (int): number of model classes\n    Returns:\n        pytorch model\n    \"\"\"",
        "detail": "yolov7.hubconf",
        "documentation": {}
    },
    {
        "label": "custom",
        "kind": 2,
        "importPath": "yolov7.hubconf",
        "description": "yolov7.hubconf",
        "peekOfCode": "def custom(path_or_model='path/to/model.pt', autoshape=True):\n    \"\"\"custom mode\n    Arguments (3 options):\n        path_or_model (str): 'path/to/model.pt'\n        path_or_model (dict): torch.load('path/to/model.pt')\n        path_or_model (nn.Module): torch.load('path/to/model.pt')['model']\n    Returns:\n        pytorch model\n    \"\"\"\n    model = torch.load(path_or_model, map_location=torch.device('cpu')) if isinstance(path_or_model, str) else path_or_model  # load checkpoint",
        "detail": "yolov7.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov7",
        "kind": 2,
        "importPath": "yolov7.hubconf",
        "description": "yolov7.hubconf",
        "peekOfCode": "def yolov7(pretrained=True, channels=3, classes=80, autoshape=True):\n    return create('yolov7', pretrained, channels, classes, autoshape)\nif __name__ == '__main__':\n    model = custom(path_or_model='yolov7.pt')  # custom example\n    # model = create(name='yolov7', pretrained=True, channels=3, classes=80, autoshape=True)  # pretrained example\n    # Verify inference\n    import numpy as np\n    from PIL import Image\n    imgs = [np.zeros((640, 480, 3))]\n    results = model(imgs)  # batched inference",
        "detail": "yolov7.hubconf",
        "documentation": {}
    },
    {
        "label": "dependencies",
        "kind": 5,
        "importPath": "yolov7.hubconf",
        "description": "yolov7.hubconf",
        "peekOfCode": "dependencies = ['torch', 'yaml']\ncheck_requirements(Path(__file__).parent / 'requirements.txt', exclude=('pycocotools', 'thop'))\nset_logging()\ndef create(name, pretrained, channels, classes, autoshape):\n    \"\"\"Creates a specified model\n    Arguments:\n        name (str): name of model, i.e. 'yolov7'\n        pretrained (bool): load pretrained weights into the model\n        channels (int): number of input channels\n        classes (int): number of model classes",
        "detail": "yolov7.hubconf",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "yolov7.test",
        "description": "yolov7.test",
        "peekOfCode": "def test(data,\n         weights=None,\n         batch_size=32,\n         imgsz=640,\n         conf_thres=0.001,\n         iou_thres=0.6,  # for NMS\n         save_json=False,\n         single_cls=False,\n         augment=False,\n         verbose=False,",
        "detail": "yolov7.test",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "yolov7.train",
        "description": "yolov7.train",
        "peekOfCode": "def train(hyp, opt, device, tb_writer=None):\n    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n    save_dir, epochs, batch_size, total_batch_size, weights, rank, freeze = \\\n        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank, opt.freeze\n    # Directories\n    wdir = save_dir / 'weights'\n    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n    last = wdir / 'last.pt'\n    best = wdir / 'best.pt'\n    results_file = save_dir / 'results.txt'",
        "detail": "yolov7.train",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov7.train",
        "description": "yolov7.train",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef train(hyp, opt, device, tb_writer=None):\n    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n    save_dir, epochs, batch_size, total_batch_size, weights, rank, freeze = \\\n        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank, opt.freeze\n    # Directories\n    wdir = save_dir / 'weights'\n    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n    last = wdir / 'last.pt'\n    best = wdir / 'best.pt'",
        "detail": "yolov7.train",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "yolov7.train_aux",
        "description": "yolov7.train_aux",
        "peekOfCode": "def train(hyp, opt, device, tb_writer=None):\n    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n    save_dir, epochs, batch_size, total_batch_size, weights, rank = \\\n        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank\n    # Directories\n    wdir = save_dir / 'weights'\n    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n    last = wdir / 'last.pt'\n    best = wdir / 'best.pt'\n    results_file = save_dir / 'results.txt'",
        "detail": "yolov7.train_aux",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov7.train_aux",
        "description": "yolov7.train_aux",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef train(hyp, opt, device, tb_writer=None):\n    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n    save_dir, epochs, batch_size, total_batch_size, weights, rank = \\\n        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank\n    # Directories\n    wdir = save_dir / 'weights'\n    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n    last = wdir / 'last.pt'\n    best = wdir / 'best.pt'",
        "detail": "yolov7.train_aux",
        "documentation": {}
    },
    {
        "label": "ClientApp",
        "kind": 6,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "class ClientApp:\n    def __init__(self):\n        self.filename = \"inputImage.jpg\"\n@app.route(\"/train\")\ndef trainRoute():\n    obj = TrainPipeline()\n    obj.run_pipeline()\n    return \n@app.route(\"/\")\ndef home():",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "trainRoute",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def trainRoute():\n    obj = TrainPipeline()\n    obj.run_pipeline()\n    return \n@app.route(\"/\")\ndef home():\n    return render_template(\"index.html\")\n@app.route(\"/predict\", methods=['POST','GET'])\n@cross_origin()\ndef predictRoute():",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def home():\n    return render_template(\"index.html\")\n@app.route(\"/predict\", methods=['POST','GET'])\n@cross_origin()\ndef predictRoute():\n    try:\n        image = request.json['image']\n        decodeImage(image, clApp.filename)\n        os.system(\"cd yolov7/ && python detect.py --weights my_model.pt  --source ../data/inputImage.jpg\")\n        opencodedbase64 = encodeImageIntoBase64(\"yolov7/runs/detect/exp/inputImage.jpg\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "predictRoute",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def predictRoute():\n    try:\n        image = request.json['image']\n        decodeImage(image, clApp.filename)\n        os.system(\"cd yolov7/ && python detect.py --weights my_model.pt  --source ../data/inputImage.jpg\")\n        opencodedbase64 = encodeImageIntoBase64(\"yolov7/runs/detect/exp/inputImage.jpg\")\n        result = {\"image\": opencodedbase64.decode('utf-8')}\n        os.system(\"rm -rf yolov7/runs\")\n    except ValueError as val:\n        print(val)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app = Flask(__name__)\nCORS(app)\nclass ClientApp:\n    def __init__(self):\n        self.filename = \"inputImage.jpg\"\n@app.route(\"/train\")\ndef trainRoute():\n    obj = TrainPipeline()\n    obj.run_pipeline()\n    return ",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "project_name",
        "kind": 5,
        "importPath": "template",
        "description": "template",
        "peekOfCode": "project_name = \"isd\"\nlist_of_files = [\n    \"data/.gitkeep\",\n    f\"{project_name}/__init__.py\",\n    f\"{project_name}/components/__init__.py\",\n    f\"{project_name}/components/data_ingestion.py\",\n    f\"{project_name}/components/data_validation.py\",\n    f\"{project_name}/components/model_trainer.py\",\n    f\"{project_name}/components/model_pusher.py\",\n    f\"{project_name}/configuration/__init__.py\",",
        "detail": "template",
        "documentation": {}
    },
    {
        "label": "list_of_files",
        "kind": 5,
        "importPath": "template",
        "description": "template",
        "peekOfCode": "list_of_files = [\n    \"data/.gitkeep\",\n    f\"{project_name}/__init__.py\",\n    f\"{project_name}/components/__init__.py\",\n    f\"{project_name}/components/data_ingestion.py\",\n    f\"{project_name}/components/data_validation.py\",\n    f\"{project_name}/components/model_trainer.py\",\n    f\"{project_name}/components/model_pusher.py\",\n    f\"{project_name}/configuration/__init__.py\",\n    f\"{project_name}/configuration/s3_operations.py\",",
        "detail": "template",
        "documentation": {}
    }
]